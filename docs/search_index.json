[
["metabolomics.html", "2 Metabolomics 2.1 Experimental methods and detailed description 2.2 Data processing 2.3 Multivariate analyses 2.4 VIPS??? 2.5 Manual annotation, identification and extraction of metabolic feature signals 2.6 Correlations", " 2 Metabolomics 2.1 Experimental methods and detailed description Additional sampling notes During the sampling on the Pâmiut cruises, the sponges remained on deck or in the laboratory for approximately 30–45 min before they were frozen to -20°C. The outside temperature usually oscillated around 4–5°C, and the sorting area was approximately 10°C. The sample consisted of both choanosome and coretx. Laboratory methods and data acquisition Metabolites were separated in connection to downstream mass spectrometry (HRMS) analysis using two different chromatographic columns (UPLC): a hydrophilic interaction liquid chromatography (HILIC) column that retains polar compounds, and a reversed-phase (RP) column that favours retention of non-polar compounds. All samples were processed in randomized order using glass instruments during the extraction to avoid chemical contamination. Mass spectrometry analysis Dried extracts in glass vials were dissolved in 200 µL solvent (HILIC: 50 µL H2O and 175 µL acetonitrile AcN; RP: 140 µL H2O and 10 µL AcN). Upon addition of the organic solvent for HILIC chromatography, all samples separated into two immiscible layers. The vials were centrifuged for 3 min at 2000 x g to yield an even separation. Only the top layer (approximately 150 µL) was transferred to a Chromacol 03-FISV MS-vial (Thermo Scientific, Waltham, Massachusetts, USA) for MS analyses. For RP chromatography, no layers were observed, and the entire volume of the dissolved sample was used. A five µL aliquot from each individual MS-vial for HILIC and RP, respectively, was combined to produce a quality control (QC) sample. High resolution MS analysis system and settings The extracts were analyzed back-to-back in positive and negative ionization mode on an Acquity I-Class Ultra Performance Liquid Chromatography UPLC coupled to a G2S Synapt Q-TOF with an electrospray ionization (ESI) ion source (all Waters Corp., Milford, MA, USA). Chromatographic separation in HILIC mode was performed on an Acquity UPLC BEH Amide column (1.7 µm, 2.1 mm inner diameter × 50 mm, Waters Corp.). Mobile phase A consisted of 95:5 acetonitrile/MQ water with 5 mM ammonium formate and 0.1 % formic acid (FA), and mobile phase B consisted of 40:60 acetonitrile/MQ water with 5 mM ammonium formate and 0.1 % FA. The gradient elution profile was as follows: mobile phase A was decreased non-linearly (slope factor 8, MassLynx) from 100 % A to 100 % B over 14 min, 100 % B was held for 2 min and then decreased back to 100 % A over 1 min. The column was re-equilibrated at 100 % A for 6 min for a total runtime of 23 min. Chromatographic separation in RP was performed on an Acquity UPLC BEH C18 column (1.7 µ m, 2.1 mm inner diameter × 50 mm, Waters). Mobile phase A consisted of MQ water with 0.1 % FA, and mobile phase B was AcN with 0.1 % FA. The gradient elution profile started at 95 % A, was decreased linearly over 14 min to 5 % A, and 5 % A was held for 2 min before the column was re-equilibrated at 95 % A for 4 min. The flow rate was set to 0.4 mL/min, the column temperature was set to 40°C, the samples were kept at 8°C and the injection volume was 5 µL in all experiments. Data acquisition Data acquisition was performed using MSE mode, and lock mass correction was applied using a solution of leucine enkephalin in both positive and negative mode. Ionization parameters were set as follows in positive/negative mode; the capillary voltage was 1kV/1.5 kV, the cone voltage was 30 V/25 V, the source offset was 50/60 and the source temperature was set to 120°C. Nitrogen was used as desolvation and cone gas with gas flows of 800 l/h and 50 l/h, respectively, and desolvation temperature was set to 500°C/450°C. For MSE acquisition a collision energy ramp from 20–45 eV was used with argon as collision gas. The instrument was calibrated in the m/z range 50–1500 using sodium formate prior to each analysis. All study samples were analysed in both RP and HILIC, in positive and negative ionization mode, resulting in four metabolite datasets per sponge specimen. The column and sample cone was cleaned in between each analysis mode. Prior to each analysis ten QC injections were made to condition the column, and to ensure stable retention times and signal intensities. The study samples were analysed in randomized order with QC injections interspaced every 6th injection. MS data processing Raw files were converted to netCDF files by Databridge (part of MassLynx, Waters Corporation, Milford, Massachusetts, USA). The netCDF files with the chromatographic spectra were sorted into folders according to species and processed with XCMS in R. Peak picking was performed using the centWave function with parameters ppm=8, peakwidth set to c(5,45) and the noise parameter set to 2000. Retention time alignment was performed with the obiwarp function and the response factor set to 10, grouping was performed with the “group” function and the “fillPeaks” function was used to impute a signal in cases where no matching pseudospectra were detected. The data set was curated to remove features eluting in the void (retention time less than 45 s). A raw data set as well as two normalized data sets (Log10-transformed and median fold change normalized) were produced and filtered to only retain features with a coefficient of variation &lt; 30% in the QC samples. After subsequent evaluation, raw data sets were used in subsequent statistics and modelling. An overview of the number of features and PC groups annotated by CAMERA, as well as their exclusion is given in a table at the end of this document. 2.2 Data processing 2.2.1 Peak picking with XCMS and annotation with CAMERA We processed samples from all three sponnge species in random order with interspersed injection of a combined QC sample to monitor stability of the UPLC-HRMS run. The acquired signals/spectra were convered to netCDF format using the Program DataBridge, and thereafter sorted into four folders, three for the sponge species (Gb, Sf, Wb) and one for the QC samples (QC). Peak picking and combination of pseudospectra is performed with the R package xcms, the subsequent annotation of adducts and isotopes with the R package CAMERA. 2.2.2 HILIC (Hydrophilic interaction chromatography) column with positive ESI (electron spray ionisation) # HILIC POS ALWAYS CHECK DATE, CHROMATOGRAPHIC CLOUMN (HILIC, RP) AND ESI-MODE # (naming, CAMERA: pos, neg) # setwd() # work in directory containing the sorted CDF files. getwd() library(xcms) xset &lt;- xcmsSet(method = &quot;centWave&quot;, ppm = 8, peakwidth = c(5, 45), noise = 2000) save(xset, file = &quot;HILIC_pos_xset_20190417.Rda&quot;) # load(file=&#39;HILIC_pos_xset_20190417.Rda&#39;) #When resuming after a break xset &lt;- group(xset) xset2 &lt;- retcor(xset, method = &quot;obiwarp&quot;, response = 10, plottype = &quot;deviation&quot;) xset2 &lt;- group(xset2) xset3 &lt;- fillPeaks(xset2) save(xset3, file = &quot;HILIC_pos_xset3_20190417.Rda&quot;) reporttab &lt;- diffreport(xset3, &quot;Gb&quot;, &quot;Sf&quot;, &quot;Gb_Sf_HILIC_pos_20190417&quot;, 10) library(CAMERA) xsa &lt;- xsAnnotate(xset3) xsaF &lt;- groupFWHM(xsa, perfwhm = 0.3) xsaC &lt;- groupCorr(xsaF, cor_eic_th = 0.7) xsaFI &lt;- findIsotopes(xsaC) rules &lt;- read.csv(&quot;data/rules_jan_pos.csv&quot;, header = T, sep = &quot;,&quot;) xsaFA &lt;- findAdducts(xsaFI, polarity = &quot;positive&quot;, rules = rules) # write.csv(getPeaklist(xsaFA), file=&#39;HILIC_pos_20190417.csv&#39;) The other data experiments, HILIC with negative ESI and RP with positive and negative ESI are processed accordingly. 2.2.3 HILIC Chromatography with negative ESI # HILIC NEG 20190421 # setwd() # work in directory containing the sorted CDF files. getwd() library(xcms) xset &lt;- xcmsSet(method = &quot;centWave&quot;, ppm = 8, peakwidth = c(5, 45), noise = 2000) save(xset, file = &quot;HILIC_neg_xset_20190421.Rda&quot;) # load(file=&#39;HILIC_neg_xset_20190421.Rda&#39;) #When resuming after a break xset &lt;- group(xset) xset2 &lt;- retcor(xset, method = &quot;obiwarp&quot;, response = 10, plottype = &quot;deviation&quot;) xset2 &lt;- group(xset2) xset3 &lt;- fillPeaks(xset2) save(xset3, file = &quot;HILIC_neg_xset3_20190421.Rda&quot;) reporttab &lt;- diffreport(xset3, &quot;Gb&quot;, &quot;Sf&quot;, &quot;Gb_Sf_HILIC_neg_20190421&quot;, 10) library(CAMERA) xsa &lt;- xsAnnotate(xset3) xsaF &lt;- groupFWHM(xsa, perfwhm = 0.3) xsaC &lt;- groupCorr(xsaF, cor_eic_th = 0.7) xsaFI &lt;- findIsotopes(xsaC) rules &lt;- read.csv(&quot;data/rules_jan_neg.csv&quot;, header = T, sep = &quot;,&quot;) xsaFA &lt;- findAdducts(xsaFI, polarity = &quot;negative&quot;, rules = rules) # write.csv(getPeaklist(xsaFA), file=&#39;HILIC_neg_20190421.csv&#39;) 2.2.4 RP (Reversed phase) Chromatography with positive ESI # RP POS 20190421 # setwd() # work in directory containing the sorted CDF files. getwd() library(xcms) xset &lt;- xcmsSet(method = &quot;centWave&quot;, ppm = 8, peakwidth = c(5, 45), noise = 2000) save(xset, file = &quot;RP_pos_xset_20190421.Rda&quot;) # load(file=&#39;RP_pos_xset_20190421.Rda&#39;) #When resuming after a break xset &lt;- group(xset) xset2 &lt;- retcor(xset, method = &quot;obiwarp&quot;, response = 10, plottype = &quot;deviation&quot;) xset2 &lt;- group(xset2) xset3 &lt;- fillPeaks(xset2) save(xset3, file = &quot;RP_pos_xset3_20190421.Rda&quot;) reporttab &lt;- diffreport(xset3, &quot;Gb&quot;, &quot;Sf&quot;, &quot;Gb_Sf_RP_pos_20190421&quot;, 10) library(CAMERA) xsa &lt;- xsAnnotate(xset3) xsaF &lt;- groupFWHM(xsa, perfwhm = 0.3) xsaC &lt;- groupCorr(xsaF, cor_eic_th = 0.7) xsaFI &lt;- findIsotopes(xsaC) rules &lt;- read.csv(&quot;data/rules_jan_pos.csv&quot;, header = T, sep = &quot;,&quot;) xsaFA &lt;- findAdducts(xsaFI, polarity = &quot;positive&quot;, rules = rules) # write.csv(getPeaklist(xsaFA), file=&#39;RP_pos_20190421.csv&#39;) 2.2.5 RP Chromatography with negative ESI # RP NEG 20190422 # setwd() # work in directory containing the sorted CDF files. getwd() library(xcms) xset &lt;- xcmsSet(method = &quot;centWave&quot;, ppm = 8, peakwidth = c(5, 45), noise = 2000) save(xset, file = &quot;RP_neg_xset_20190422.Rda&quot;) # load(file=&#39;RP_neg_xset_20190422.Rda&#39;) #When resuming after a break xset &lt;- group(xset) xset2 &lt;- retcor(xset, method = &quot;obiwarp&quot;, response = 10, plottype = &quot;deviation&quot;) xset2 &lt;- group(xset2) xset3 &lt;- fillPeaks(xset2) save(xset3, file = &quot;RP_neg_xset3_20190422.Rda&quot;) reporttab &lt;- diffreport(xset3, &quot;Gb&quot;, &quot;Sf&quot;, &quot;Gb_Sf_RP_neg_20190422&quot;, 10) library(CAMERA) xsa &lt;- xsAnnotate(xset3) xsaF &lt;- groupFWHM(xsa, perfwhm = 0.3) xsaC &lt;- groupCorr(xsaF, cor_eic_th = 0.7) xsaFI &lt;- findIsotopes(xsaC) rules &lt;- read.csv(&quot;data/rules_jan_neg.csv&quot;, header = T, sep = &quot;,&quot;) xsaFA &lt;- findAdducts(xsaFI, polarity = &quot;negative&quot;, rules = rules) # write.csv(getPeaklist(xsaFA), file=&#39;RP_neg_20190422.csv&#39;) 2.2.6 Filtering of the raw data set Features with with following properties were removed: Eluting in the void (RT &lt; 45 s) CV&gt;30 % in QC samples Adducts as annotated by CAMERA As the presence of the same parent feature in the the form of isotopes and adducts distorts downstream global metabolome analyses, we generated two versions of curated or selective feature tables. In both, void and unstably measured features are removed (“cleaned”). One retains only the feature with the largest signal per pc group (“cleaned_pcgroup”), the other is more stringent and only contains explicitly annotated parent ions (“cleaned_MH”), i.e. [M+H]+ for positive ESI and [M-H]- for negative ESI acquired data. library(dplyr) # ================================ HILIC pos =================================== raw_peaks &lt;- read.csv(&quot;data/HILIC_pos_20190417.csv&quot;) hp_dim1 &lt;- dim(raw_peaks)[1] hp_pcg1 &lt;- length(unique(raw_peaks$pcgroup)) # Removing features eluting in the void raw_peaks &lt;- raw_peaks[raw_peaks$rt &gt; 45, ] hp_dim2 &lt;- dim(raw_peaks)[1] hp_pcg2 &lt;- length(unique(raw_peaks$pcgroup)) # Removing features with a CV &lt; 30% f &lt;- which(colnames(raw_peaks) == &quot;IE_20170918_02001&quot;) # first QC HILIC pos l &lt;- which(colnames(raw_peaks) == &quot;IE_20170918_07601&quot;) # last QC HILIC pos raw_peaks[&quot;SD&quot;] &lt;- apply(raw_peaks[, f:l], 1, sd) raw_peaks[&quot;MEAN&quot;] &lt;- apply(raw_peaks[, f:l], 1, mean) raw_peaks[&quot;CV&quot;] &lt;- raw_peaks$SD/raw_peaks$MEAN raw_peaks &lt;- raw_peaks[raw_peaks$CV &lt; 0.3, ] hp_dim3 &lt;- dim(raw_peaks)[1] hp_pcg3 &lt;- length(unique(raw_peaks$pcgroup)) # write.csv(raw_peaks, &#39;HILIC_pos_20190417_cleaned.csv&#39;) # Keep only the feature with the greatest sum of signal per pc group l &lt;- dim(raw_peaks)[2] - 6 raw_peaks[&quot;fss&quot;] &lt;- apply(raw_peaks[, 13:l], 1, sum) #feature signal sum raw_peaks &lt;- raw_peaks[order(raw_peaks$pcgroup, -raw_peaks$fss), ] # for every pc group, the first line has the strongest signal. The function # distinct() [dplyr package] can be used to keep only unique/distinct rows from a # data frame. If there are duplicate rows, _only the first row_ is preserved. selected_peaks &lt;- distinct(raw_peaks, raw_peaks$pcgroup, .keep_all = TRUE) hp_dim4 &lt;- dim(selected_peaks)[1] hp_pcg4 &lt;- length(unique(selected_peaks$pcgroup)) # write.csv(selected_peaks, &#39;HILIC_pos_20190417_cleaned_pcgroup.csv&#39;) rm(selected_peaks) # Keep only features with explicit annotations of [M+H]+ library(stringr) raw_peaks[&quot;[M+H]+&quot;] &lt;- NA pattern &lt;- &quot;[M+H]+&quot; raw_peaks[&quot;[M+H]+&quot;] &lt;- str_detect(raw_peaks$adduct, paste0(&quot;^\\\\Q&quot;, pattern, &quot;\\\\E&quot;)) selected_peaks &lt;- raw_peaks[raw_peaks$`[M+H]+` == &quot;TRUE&quot;, ] hp_dim5 &lt;- dim(selected_peaks)[1] hp_pcg5 &lt;- length(unique(selected_peaks$pcgroup)) # write.csv(selected_peaks, &#39;HILIC_pos_20190417_cleaned_MH.csv&#39;) hilic_pos &lt;- raw_peaks rm(f, l, raw_peaks, selected_peaks) # ================================ HILIC neg =================================== raw_peaks &lt;- read.csv(&quot;data/HILIC_neg_20190421.csv&quot;) hn_dim1 &lt;- dim(raw_peaks)[1] hn_pcg1 &lt;- length(unique(raw_peaks$pcgroup)) # Removing features eluting in the void raw_peaks &lt;- raw_peaks[raw_peaks$rt &gt; 45, ] hn_dim2 &lt;- dim(raw_peaks)[1] hn_pcg2 &lt;- length(unique(raw_peaks$pcgroup)) # Removing features with a CV &lt; 30% f &lt;- which(colnames(raw_peaks) == &quot;IE_20170919_01301&quot;) # first QC HILIC neg l &lt;- which(colnames(raw_peaks) == &quot;IE_20170919_06901&quot;) # last QC HILIC neg raw_peaks[&quot;SD&quot;] &lt;- apply(raw_peaks[, f:l], 1, sd) raw_peaks[&quot;MEAN&quot;] &lt;- apply(raw_peaks[, f:l], 1, mean) raw_peaks[&quot;CV&quot;] &lt;- raw_peaks$SD/raw_peaks$MEAN raw_peaks &lt;- raw_peaks[raw_peaks$CV &lt; 0.3, ] hn_dim3 &lt;- dim(raw_peaks)[1] hn_pcg3 &lt;- length(unique(raw_peaks$pcgroup)) # write.csv(raw_peaks, &#39;HILIC_neg_20190421_cleaned.csv&#39;) # Keep only the feature with the greatest sum of signal per pc group l &lt;- dim(raw_peaks)[2] - 6 raw_peaks[&quot;fss&quot;] &lt;- apply(raw_peaks[, 13:l], 1, sum) #feature signal sum raw_peaks &lt;- raw_peaks[order(raw_peaks$pcgroup, -raw_peaks$fss), ] selected_peaks &lt;- distinct(raw_peaks, raw_peaks$pcgroup, .keep_all = TRUE) hn_dim4 &lt;- dim(selected_peaks)[1] hn_pcg4 &lt;- length(unique(selected_peaks$pcgroup)) # write.csv(selected_peaks, &#39;HILIC_neg_20190421_cleaned_pcgroup.csv&#39;) rm(selected_peaks) # Keep only features with explicit annotations of [M-H]- library(stringr) raw_peaks[&quot;[M-H]-&quot;] &lt;- NA pattern &lt;- &quot;[M-H]-&quot; raw_peaks[&quot;[M-H]-&quot;] &lt;- str_detect(raw_peaks$adduct, paste0(&quot;^\\\\Q&quot;, pattern, &quot;\\\\E&quot;)) selected_peaks &lt;- raw_peaks[raw_peaks$`[M-H]-` == &quot;TRUE&quot;, ] hn_dim5 &lt;- dim(selected_peaks)[1] hn_pcg5 &lt;- length(unique(selected_peaks$pcgroup)) # write.csv(selected_peaks, &#39;HILIC_neg_20190421_cleaned_MH.csv&#39;) hilic_neg &lt;- raw_peaks rm(f, l, raw_peaks) # ================================== RP pos ==================================== raw_peaks &lt;- read.csv(&quot;data/RP_pos_20190421.csv&quot;) rp_dim1 &lt;- dim(raw_peaks)[1] rp_pcg1 &lt;- length(unique(raw_peaks$pcgroup)) # Removing features eluting in the void raw_peaks &lt;- raw_peaks[raw_peaks$rt &gt; 45, ] rp_dim2 &lt;- dim(raw_peaks)[1] rp_pcg2 &lt;- length(unique(raw_peaks$pcgroup)) # Removing features with a CV &lt; 30% f &lt;- which(colnames(raw_peaks) == &quot;IE_20171002_01401&quot;) # first QC RP neg l &lt;- which(colnames(raw_peaks) == &quot;IE_20171002_07201&quot;) # last QC RP neg raw_peaks[&quot;SD&quot;] &lt;- apply(raw_peaks[, f:l], 1, sd) raw_peaks[&quot;MEAN&quot;] &lt;- apply(raw_peaks[, f:l], 1, mean) raw_peaks[&quot;CV&quot;] &lt;- raw_peaks$SD/raw_peaks$MEAN raw_peaks &lt;- raw_peaks[raw_peaks$CV &lt; 0.3, ] rp_dim3 &lt;- dim(raw_peaks)[1] rp_pcg3 &lt;- length(unique(raw_peaks$pcgroup)) # write.csv(raw_peaks, &#39;RP_pos_20190421_cleaned.csv&#39;) # Keep only the feature with the greatest sum of signal per pc group l &lt;- dim(raw_peaks)[2] - 6 raw_peaks[&quot;fss&quot;] &lt;- apply(raw_peaks[, 13:l], 1, sum) #feature signal sum raw_peaks &lt;- raw_peaks[order(raw_peaks$pcgroup, -raw_peaks$fss), ] selected_peaks &lt;- distinct(raw_peaks, raw_peaks$pcgroup, .keep_all = TRUE) rp_dim4 &lt;- dim(selected_peaks)[1] rp_pcg4 &lt;- length(unique(selected_peaks$pcgroup)) # write.csv(selected_peaks, &#39;RP_pos_20190421_cleaned_pcgroup.csv&#39;) rm(selected_peaks) # Keep only features with explicit annotations of [M+H]+ library(stringr) raw_peaks[&quot;[M+H]+&quot;] &lt;- NA pattern &lt;- &quot;[M+H]+&quot; raw_peaks[&quot;[M+H]+&quot;] &lt;- str_detect(raw_peaks$adduct, paste0(&quot;^\\\\Q&quot;, pattern, &quot;\\\\E&quot;)) selected_peaks &lt;- raw_peaks[raw_peaks$`[M+H]+` == &quot;TRUE&quot;, ] rp_dim5 &lt;- dim(selected_peaks)[1] rp_pcg5 &lt;- length(unique(selected_peaks$pcgroup)) # write.csv(selected_peaks, &#39;RP_pos_20190421_cleaned_MH.csv&#39;) rp_pos &lt;- raw_peaks rm(f, l, raw_peaks, selected_peaks) # ================================== RP neg ==================================== raw_peaks &lt;- read.csv(&quot;data/RP_neg_20190422.csv&quot;) rn_dim1 &lt;- dim(raw_peaks)[1] rn_pcg1 &lt;- length(unique(raw_peaks$pcgroup)) # Removing features eluting in the void raw_peaks &lt;- raw_peaks[raw_peaks$rt &gt; 45, ] rn_dim2 &lt;- dim(raw_peaks)[1] rn_pcg2 &lt;- length(unique(raw_peaks$pcgroup)) # Removing features with a CV &lt; 30% f &lt;- which(colnames(raw_peaks) == &quot;IE_20171003_01301&quot;) # first QC RP neg l &lt;- which(colnames(raw_peaks) == &quot;IE_20171003_05701&quot;) # 3rd last QC RP neg; QC empty after this injection raw_peaks[&quot;SD&quot;] &lt;- apply(raw_peaks[, f:l], 1, sd) raw_peaks[&quot;MEAN&quot;] &lt;- apply(raw_peaks[, f:l], 1, mean) raw_peaks[&quot;CV&quot;] &lt;- raw_peaks$SD/raw_peaks$MEAN raw_peaks &lt;- raw_peaks[raw_peaks$CV &lt; 0.3, ] rn_dim3 &lt;- dim(raw_peaks)[1] rn_pcg3 &lt;- length(unique(raw_peaks$pcgroup)) # write.csv(raw_peaks, &#39;RP_neg_20190422_cleaned.csv&#39;) # Keep only the feature with the greatest sum of signal per pc group l &lt;- dim(raw_peaks)[2] - 6 raw_peaks[&quot;fss&quot;] &lt;- apply(raw_peaks[, 13:l], 1, sum) #feature signal sum raw_peaks &lt;- raw_peaks[order(raw_peaks$pcgroup, -raw_peaks$fss), ] selected_peaks &lt;- distinct(raw_peaks, raw_peaks$pcgroup, .keep_all = TRUE) rn_dim4 &lt;- dim(selected_peaks)[1] rn_pcg4 &lt;- length(unique(selected_peaks$pcgroup)) # write.csv(selected_peaks, &#39;RP_neg_20190422_cleaned_pcgroup.csv&#39;) rm(selected_peaks) # Keep only features with explicit annotations of [M-H]- library(stringr) raw_peaks[&quot;[M-H]-&quot;] &lt;- NA pattern &lt;- &quot;[M-H]-&quot; raw_peaks[&quot;[M-H]-&quot;] &lt;- str_detect(raw_peaks$adduct, paste0(&quot;^\\\\Q&quot;, pattern, &quot;\\\\E&quot;)) selected_peaks &lt;- raw_peaks[raw_peaks$`[M-H]-` == &quot;TRUE&quot;, ] rn_dim5 &lt;- dim(selected_peaks)[1] rn_pcg5 &lt;- length(unique(selected_peaks$pcgroup)) # write.csv(selected_peaks, &#39;RP_neg_20190422_cleaned_MH.csv&#39;) hilic_neg &lt;- raw_peaks rm(f, l, raw_peaks, selected_peaks) 2.2.7 Data quality control To monitor the stability of the signal during the UPLC-HRMS run, we plot the total signal per sample by injection order. hp &lt;- read.csv(&quot;data/HILIC_pos_20190417.csv&quot;, header = T, sep = &quot;,&quot;) hn &lt;- read.csv(&quot;data/HILIC_neg_20190421.csv&quot;, header = T, sep = &quot;,&quot;) rp &lt;- read.csv(&quot;data/RP_pos_20190421.csv&quot;, header = T, sep = &quot;,&quot;) rn &lt;- read.csv(&quot;data/RP_neg_20190422.csv&quot;, header = T, sep = &quot;,&quot;) # subsetting, keep only sample data hp &lt;- hp[, 13:(dim(hp)[2] - 3)] #14 hn &lt;- hn[, 13:(dim(hn)[2] - 3)] rp &lt;- rp[, 13:(dim(rp)[2] - 3)] rn &lt;- rn[, 13:(dim(rn)[2] - 3)] # sum signal of columns, i.e. per sample hp[nrow(hp) + 1, ] &lt;- apply(hp, 2, sum) hn[nrow(hn) + 1, ] &lt;- apply(hn, 2, sum) rp[nrow(rp) + 1, ] &lt;- apply(rp, 2, sum) rn[nrow(rn) + 1, ] &lt;- apply(rn, 2, sum) # data frame gymnastics hp_df &lt;- data.frame(t((hp[dim(hp)[1], ]))) hn_df &lt;- data.frame(t((hn[dim(hn)[1], ]))) rp_df &lt;- data.frame(t((rp[dim(rp)[1], ]))) rn_df &lt;- data.frame(t((rn[dim(rn)[1], ]))) colnames(hp_df) &lt;- c(&quot;colsum_hp&quot;) hp_df[&quot;id&quot;] &lt;- rownames(hp_df) colnames(hn_df) &lt;- c(&quot;colsum_hn&quot;) hn_df[&quot;id&quot;] &lt;- rownames(hn_df) colnames(rp_df) &lt;- c(&quot;colsum_rp&quot;) rp_df[&quot;id&quot;] &lt;- rownames(rp_df) colnames(rn_df) &lt;- c(&quot;colsum_rn&quot;) rn_df[&quot;id&quot;] &lt;- rownames(rn_df) library(stringr) hp_df[&quot;hp_io&quot;] &lt;- as.integer(str_sub(hp_df$id, -4, -3)) hn_df[&quot;hn_io&quot;] &lt;- as.integer(str_sub(hn_df$id, -4, -3)) rp_df[&quot;rp_io&quot;] &lt;- as.integer(str_sub(rp_df$id, -4, -3)) rn_df[&quot;rn_io&quot;] &lt;- as.integer(str_sub(rn_df$id, -4, -3)) hp_df &lt;- hp_df[order(hp_df$hp_io), ] hp_df[&quot;n&quot;] &lt;- seq(nrow(hp_df)) hp_df[&quot;experiment&quot;] &lt;- &quot;HILIC pos.&quot; hn_df &lt;- hn_df[order(hn_df$hn_io), ] hn_df[&quot;n&quot;] &lt;- seq(nrow(hn_df)) hn_df[&quot;experiment&quot;] &lt;- &quot;HILIC neg.&quot; rp_df &lt;- rp_df[order(rp_df$rp_io), ] rp_df[&quot;n&quot;] &lt;- seq(nrow(rp_df)) rp_df[&quot;experiment&quot;] &lt;- &quot;RP pos.&quot; rn_df &lt;- rn_df[order(rn_df$rn_io), ] rn_df[&quot;n&quot;] &lt;- seq(nrow(rn_df)) rn_df[&quot;experiment&quot;] &lt;- &quot;RP neg.&quot; colnames(hp_df) &lt;- c(&quot;colsum&quot;, &quot;id&quot;, &quot;io&quot;, &quot;n&quot;, &quot;experiment&quot;) colnames(hn_df) &lt;- c(&quot;colsum&quot;, &quot;id&quot;, &quot;io&quot;, &quot;n&quot;, &quot;experiment&quot;) colnames(rp_df) &lt;- c(&quot;colsum&quot;, &quot;id&quot;, &quot;io&quot;, &quot;n&quot;, &quot;experiment&quot;) colnames(rn_df) &lt;- c(&quot;colsum&quot;, &quot;id&quot;, &quot;io&quot;, &quot;n&quot;, &quot;experiment&quot;) stability &lt;- rbind(hp_df, hn_df, rp_df, rn_df) library(ggplot2) ggplot(stability, aes(x = n, y = colsum, color = experiment)) + geom_line(size = 1.5) + ggtitle(&quot;Signal intensity during UPLC-HRMS experiments&quot;) + xlab(&quot;sample injection order&quot;) + ylab(&quot;total signal intensity per sample&quot;) + labs(colour = &quot;Experiment&quot;) + theme(legend.position = &quot;bottom&quot;) + geom_smooth(method = &quot;lm&quot;, size = 0.5) + facet_grid(experiment ~ ., scales = &quot;free&quot;) rm(hp, hp_df, hn, hn_df, rp, rp_df, rn, rn_df, stability) 2.2.8 Summary of data processing Below we outline the number of features removed in every step as shown in the table and corresponding figure. initial_f &lt;- c(hp_dim1, hn_dim1, rp_dim1, rn_dim1) rt_f &lt;- c(hp_dim2, hn_dim2, rp_dim2, rn_dim2) cv_f &lt;- c(hp_dim3, hn_dim3, rp_dim3, rn_dim3) representative_f &lt;- c(hp_dim4, hn_dim4, rp_dim4, rn_dim4) ion_f &lt;- c(hp_dim5, hn_dim5, rp_dim5, rn_dim5) initial_p &lt;- c(hp_pcg1, hn_pcg1, rp_pcg1, rn_pcg1) rt_p &lt;- c(hp_pcg2, hn_pcg2, rp_pcg2, rn_pcg2) cv_p &lt;- c(hp_pcg3, hn_pcg3, rp_pcg3, rn_pcg3) representative_p &lt;- c(hp_pcg4, hn_pcg4, rp_pcg4, rn_pcg4) ion_p &lt;- c(hp_pcg5, hn_pcg5, rp_pcg5, rn_pcg5) df &lt;- cbind(initial_f, rt_f, cv_f, representative_f, ion_f, initial_p, rt_p, cv_p, representative_p, ion_p) rownames(df) &lt;- c(&quot;HILIC pos&quot;, &quot;HILIC neg&quot;, &quot;RP pos&quot;, &quot;RP neg&quot;) library(kableExtra) kable(df, col.names = c(&quot;initial&quot;, &quot;RT &gt;45 s&quot;, &quot;CV &lt;30%&quot;, &quot;repr. feat.&quot;, &quot;ion&quot;, &quot;initial&quot;, &quot;RT &gt;45 s&quot;, &quot;CV &lt;30%&quot;, &quot;repr. feat.&quot;, &quot;ion&quot;), longtable = T, booktabs = T, caption = &quot;Number of features and pc groups remaining after each filtering step.&quot;) %&gt;% add_header_above(c(&quot;&quot;, features = 5, `pc groups` = 5)) %&gt;% kable_styling(bootstrap_options = &quot;condensed&quot;, full_width = T) (#tab:kable_table)Number of features and pc groups remaining after each filtering step. features pc groups initial RT &gt;45 s CV &lt;30% repr. feat. ion initial RT &gt;45 s CV &lt;30% repr. feat. ion HILIC pos 5113 4389 3507 2212 105 3298 2781 2212 2212 79 HILIC neg 4049 3081 2808 1351 123 2044 1495 1351 1351 62 RP pos 5821 5588 4673 2736 171 3420 3277 2736 2736 128 RP neg 3867 3621 3166 1678 105 2069 1918 1678 1678 80 library(reshape2) df &lt;- melt(df) df[&quot;filter&quot;] &lt;- c(rep((&quot;initial&quot;), 4), rep((&quot;RT &gt;45 s&quot;), 4), rep((&quot;CV &lt;30%&quot;), 4), rep((&quot;rep&quot;), 4), rep((&quot;ion&quot;), 4)) df$filter &lt;- factor(df$filter, levels = c(&quot;initial&quot;, &quot;RT &gt;45 s&quot;, &quot;CV &lt;30%&quot;, &quot;rep&quot;, &quot;ion&quot;)) df[&quot;category&quot;] &lt;- c(rep((&quot;feature&quot;), 20), rep((&quot;pc group&quot;), 20)) df$Var2 &lt;- NULL colnames(df) &lt;- c(&quot;acquisition&quot;, &quot;value&quot;, &quot;filter&quot;, &quot;category&quot;) library(ggplot2) ggplot(df, aes(fill = df$filter, x = df$acquisition, y = df$value)) + geom_bar(position = &quot;dodge&quot;, stat = &quot;identity&quot;) + facet_grid(. ~ df$category) + xlab(&quot;Data acquisition mode&quot;) + ylab(&quot;Count&quot;) + labs(fill = &quot;Filtering step&quot;) + theme_bw() + scale_fill_grey() + scale_y_continuous(breaks = seq(0, 6000, 1000)) + theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust = 0.5), legend.position = &quot;bottom&quot;) After preliminary analyses of metabolomics data, a few outliers were re-identified by P. Cárdenas, and one specimen was removed from the data set as it originated from another species. 2.3 Multivariate analyses I order to investigate whether depth has an effect on the overall metabolome, we use OPLS orthogonal projections of latent structures as multivariate analysis approach. This method allows to separate variations in the data based on e.g. depth and orthogonal, i.e. unrealted variation. library(ropls) library(dplyr) library(ggplot2) library(tidyverse) library(vegan) # load data hilic_pos &lt;- read.csv(&quot;data/HILIC_pos_20190417_cleaned.csv&quot;, header = T, sep = &quot;,&quot;) hilic_neg &lt;- read.csv(&quot;data/HILIC_neg_20190421_cleaned.csv&quot;, header = T, sep = &quot;,&quot;) rp_pos &lt;- read.csv(&quot;data/RP_pos_20190421_cleaned.csv&quot;, header = T, sep = &quot;,&quot;) rp_neg &lt;- read.csv(&quot;data/RP_neg_20190422_cleaned.csv&quot;, header = T, sep = &quot;,&quot;) meta_data &lt;- read.csv(&quot;data/Steffen_et_al_metadata_PANGAEA.csv&quot;, header = T, sep = &quot;;&quot;) formatting &lt;- function(metabolome, meta_data, r, my_colnames) { formatted &lt;- metabolome formatted &lt;- formatted[, 14:(dim(formatted)[2] - r)] formatted &lt;- data.frame(t(formatted)) formatted[&quot;ID&quot;] &lt;- rownames(formatted) formatted[&quot;unified_ID&quot;] &lt;- meta_data$unified_ID[match(formatted$ID, meta_data[[my_colnames]])] formatted[&quot;filter&quot;] &lt;- str_sub(formatted$unified_ID, 1, 2) formatted &lt;- formatted[!formatted$filter == &quot;QC&quot;, ] formatted &lt;- na.omit(formatted) # formatted$filter &lt;- NULL formatted$ID &lt;- NULL formatted &lt;- formatted[order(formatted$unified_ID), ] rownames(formatted) &lt;- formatted$unified_ID return(formatted) } hilic_pos &lt;- formatting(hilic_pos, meta_data, 6, &quot;LC.MS.HILIC.positive&quot;) hilic_neg &lt;- formatting(hilic_neg, meta_data, 6, &quot;LC.MS.HILIC.negative&quot;) rp_pos &lt;- formatting(rp_pos, meta_data, 6, &quot;LC.MS.RP.positive&quot;) rp_neg &lt;- formatting(rp_neg, meta_data, 6, &quot;LC.MS.RP.negative&quot;) md &lt;- meta_data[, c(&quot;Species&quot;, &quot;Depth&quot;, &quot;Latitude&quot;, &quot;Longitude&quot;, &quot;YEAR&quot;, &quot;MeanBottomTemp_Cdeg&quot;, &quot;MeanBotSalinity_PSU&quot;, &quot;unified_ID&quot;)] # Overview PCA illustrating the metabolomes differ by sponge species pca_wrapper &lt;- function(metabolome, md, my_title) { metabolome$unified_ID &lt;- NULL metabolome$filter &lt;- NULL metabolome &lt;- prcomp(metabolome, scale = T) k &lt;- summary(metabolome)[[&quot;importance&quot;]] metabolome_df &lt;- data.frame(metabolome$x) #scores, i.e. principal components of the sponge sample metabolome_df[&quot;unified_ID&quot;] &lt;- as.factor(rownames(metabolome_df)) x1 &lt;- paste(&quot;PC1&quot;, round(k[2, 1], digits = 3) * 100, &quot;%&quot;) y1 &lt;- paste(&quot;PC2&quot;, round(k[2, 2], digits = 3) * 100, &quot;%&quot;) metabolome_df &lt;- left_join(metabolome_df[, c(&quot;PC1&quot;, &quot;PC2&quot;, &quot;PC3&quot;, &quot;unified_ID&quot;)], md[, c(&quot;Species&quot;, &quot;Depth&quot;, &quot;Latitude&quot;, &quot;Longitude&quot;, &quot;MeanBottomTemp_Cdeg&quot;, &quot;MeanBotSalinity_PSU&quot;, &quot;unified_ID&quot;)]) p &lt;- ggplot(metabolome_df, aes(x = PC1, y = PC2)) + geom_point(size = 3, aes(shape = factor(Species))) + ggtitle(my_title) + xlab(x1) + ylab(y1) + theme(legend.position = &quot;none&quot;) #+labs(shape=&#39;Species&#39;) return(p) } hp_pca &lt;- pca_wrapper(hilic_pos, md, &quot;Hilic pos&quot;) hn_pca &lt;- pca_wrapper(hilic_neg, md, &quot;Hilic neg&quot;) rp_pca &lt;- pca_wrapper(rp_pos, md, &quot;RP pos&quot;) rn_pca &lt;- pca_wrapper(rp_neg, md, &quot;RP pos&quot;) # FUN multiplot # NOT MY OWN multiplot &lt;- function(..., plotlist = NULL, file, cols = 1, layout = NULL) { library(grid) # Make a list from the ... arguments and plotlist plots &lt;- c(list(...), plotlist) numPlots = length(plots) # If layout is NULL, then use &#39;cols&#39; to determine layout if (is.null(layout)) { # Make the panel ncol: Number of columns of plots nrow: Number of rows needed, # calculated from # of cols layout &lt;- matrix(seq(1, cols * ceiling(numPlots/cols)), ncol = cols, nrow = ceiling(numPlots/cols)) } if (numPlots == 1) { print(plots[[1]]) } else { # Set up the page grid.newpage() pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout)))) # Make each plot, in the correct location for (i in 1:numPlots) { # Get the i,j matrix positions of the regions that contain this subplot matchidx &lt;- as.data.frame(which(layout == i, arr.ind = TRUE)) print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row, layout.pos.col = matchidx$col)) } } } multiplot(hp_pca, hn_pca, rp_pca, rn_pca, cols = 2) library(vegan) permanova &lt;- function(metabolome, md) { metabolome$filter &lt;- NULL md &lt;- md[md$unified_ID %in% metabolome$unified_ID, ] metabolome &lt;- metabolome[order(metabolome$unified_ID), ] md &lt;- md[order(md$unified_ID), ] metabolome$unified_ID &lt;- NULL m &lt;- adonis(metabolome ~ Species, md) return(m) } permanova(hilic_pos, md) ## ## Call: ## adonis(formula = metabolome ~ Species, data = md) ## ## Permutation: free ## Number of permutations: 999 ## ## Terms added sequentially (first to last) ## ## Df SumsOfSqs MeanSqs F.Model R2 Pr(&gt;F) ## Species 2 5.6422 2.82112 34.302 0.62026 0.001 *** ## Residuals 42 3.4543 0.08224 0.37974 ## Total 44 9.0965 1.00000 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 permanova(hilic_neg, md) ## ## Call: ## adonis(formula = metabolome ~ Species, data = md) ## ## Permutation: free ## Number of permutations: 999 ## ## Terms added sequentially (first to last) ## ## Df SumsOfSqs MeanSqs F.Model R2 Pr(&gt;F) ## Species 2 2.0768 1.03838 26.046 0.55363 0.001 *** ## Residuals 42 1.6744 0.03987 0.44637 ## Total 44 3.7512 1.00000 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 permanova(rp_pos, md) ## ## Call: ## adonis(formula = metabolome ~ Species, data = md) ## ## Permutation: free ## Number of permutations: 999 ## ## Terms added sequentially (first to last) ## ## Df SumsOfSqs MeanSqs F.Model R2 Pr(&gt;F) ## Species 2 6.0969 3.04847 35.972 0.6314 0.001 *** ## Residuals 42 3.5593 0.08475 0.3686 ## Total 44 9.6563 1.0000 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 permanova(rp_neg, md) ## ## Call: ## adonis(formula = metabolome ~ Species, data = md) ## ## Permutation: free ## Number of permutations: 999 ## ## Terms added sequentially (first to last) ## ## Df SumsOfSqs MeanSqs F.Model R2 Pr(&gt;F) ## Species 2 6.4179 3.2089 36.013 0.63725 0.001 *** ## Residuals 41 3.6533 0.0891 0.36275 ## Total 43 10.0712 1.00000 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 From the PCA and the PERMANOVA, we gather that the metabolomes regardless of how they were acquired are significatly different in the three sponge species. Therefore, we separate the metabolomes for investigating the effect of depth on them individually. # splitting df and adapting meta data spl_ada &lt;- function(metabolome, md) { metabolome_gb &lt;- metabolome[metabolome$filter == &quot;Gb&quot;, ] metabolome_sf &lt;- metabolome[metabolome$filter == &quot;Sf&quot;, ] metabolome_wb &lt;- metabolome[metabolome$filter == &quot;Wb&quot;, ] md_gb &lt;- md[md$unified_ID %in% metabolome_gb$unified_ID, ] md_sf &lt;- md[md$unified_ID %in% metabolome_sf$unified_ID, ] md_wb &lt;- md[md$unified_ID %in% metabolome_wb$unified_ID, ] metabolome_gb &lt;- metabolome_gb[order(metabolome_gb$unified_ID), ] metabolome_sf &lt;- metabolome_sf[order(metabolome_sf$unified_ID), ] metabolome_wb &lt;- metabolome_wb[order(metabolome_wb$unified_ID), ] metabolome_gb$filter &lt;- NULL metabolome_gb$unified_ID &lt;- NULL metabolome_sf$filter &lt;- NULL metabolome_sf$unified_ID &lt;- NULL metabolome_wb$filter &lt;- NULL metabolome_wb$unified_ID &lt;- NULL md_gb &lt;- md_gb[order(md_gb$unified_ID), ] md_sf &lt;- md_sf[order(md_sf$unified_ID), ] md_wb &lt;- md_wb[order(md_wb$unified_ID), ] mva_data &lt;- list(metabolome_gb = metabolome_gb, metabolome_sf = metabolome_sf, metabolome_wb = metabolome_wb, md_gb = md_gb, md_sf = md_sf, md_wb = md_wb) return(mva_data) } hp_opls_df &lt;- spl_ada(hilic_pos, md) hn_opls_df &lt;- spl_ada(hilic_neg, md) rp_opls_df &lt;- spl_ada(rp_pos, md) rn_opls_df &lt;- spl_ada(rp_neg, md) # P should be NA; or 1 ropls_wrapper &lt;- function(opls_df, p1, p2, p3) { # ropls&#39; PCA gb.pca &lt;- opls(opls_df$metabolome_gb, plotL = F, printL = F) sf.pca &lt;- opls(opls_df$metabolome_sf, plotL = F, printL = F) wb.pca &lt;- opls(opls_df$metabolome_wb, plotL = F, printL = F) md_gb &lt;- opls_df$md_gb md_sf &lt;- opls_df$md_sf md_wb &lt;- opls_df$md_wb # ropls&#39; OPLS gb.opls &lt;- opls(opls_df$metabolome_gb, md_gb[, &quot;Depth&quot;], permI = 1000, orthoI = p1, scaleC = &quot;pareto&quot;, plotL = F) sf.opls &lt;- opls(opls_df$metabolome_sf, md_sf[, &quot;Depth&quot;], permI = 1000, orthoI = p2, scaleC = &quot;pareto&quot;, plotL = F) wb.opls &lt;- opls(opls_df$metabolome_wb, md_wb[, &quot;Depth&quot;], permI = 1000, orthoI = p3, scaleC = &quot;pareto&quot;, plotL = F) # summary gb.opls &lt;- gb.opls@summaryDF sf.opls &lt;- sf.opls@summaryDF wb.opls &lt;- wb.opls@summaryDF opls_diagnostics &lt;- rbind(gb.opls, sf.opls, wb.opls) opls_diagnostics[&quot;Species&quot;] &lt;- c(&quot;Geodia barretti&quot;, &quot;Stryphnus fortis&quot;, &quot;Weberella bursa&quot;) return(opls_diagnostics) } a &lt;- Sys.time() hp_cleaned_opls &lt;- ropls_wrapper(hp_opls_df, NA, 1, NA) hn_cleaned_opls &lt;- ropls_wrapper(hn_opls_df, NA, 1, NA) rp_cleaned_opls &lt;- ropls_wrapper(rp_opls_df, NA, 1, NA) rn_cleaned_opls &lt;- ropls_wrapper(rn_opls_df, 1, 1, NA) b &lt;- Sys.time() b - a cleaned &lt;- rbind(hp_cleaned_opls, hn_cleaned_opls, rp_cleaned_opls, rn_cleaned_opls) cleaned[&quot;Experiment&quot;] &lt;- c(rep(&quot;HILIC pos&quot;, 3), rep(&quot;HILIC neg&quot;, 3), rep(&quot;RP pos&quot;, 3), rep(&quot;RP neg&quot;, 3)) write.csv(cleaned, &quot;data/cleaned_opls_diagnostics.csv&quot;, row.names = F) In the same manner, we can analyse the two remaining sets produced by different filtering options. # load data ION hilic_pos &lt;- read.csv(&quot;data/HILIC_pos_20190417_cleaned_MH.csv&quot;, header = T, sep = &quot;,&quot;) hilic_neg &lt;- read.csv(&quot;data/HILIC_neg_20190421_cleaned_MH.csv&quot;, header = T, sep = &quot;,&quot;) rp_pos &lt;- read.csv(&quot;data/RP_pos_20190421_cleaned_MH.csv&quot;, header = T, sep = &quot;,&quot;) rp_neg &lt;- read.csv(&quot;data/RP_neg_20190422_cleaned_MH.csv&quot;, header = T, sep = &quot;,&quot;) meta_data &lt;- read.csv(&quot;data/Steffen_et_al_metadata_PANGAEA.csv&quot;, header = T, sep = &quot;;&quot;) hilic_pos &lt;- formatting(hilic_pos, meta_data, 8, &quot;LC.MS.HILIC.positive&quot;) hilic_neg &lt;- formatting(hilic_neg, meta_data, 8, &quot;LC.MS.HILIC.negative&quot;) rp_pos &lt;- formatting(rp_pos, meta_data, 8, &quot;LC.MS.RP.positive&quot;) rp_neg &lt;- formatting(rp_neg, meta_data, 8, &quot;LC.MS.RP.negative&quot;) md &lt;- meta_data[, c(&quot;Species&quot;, &quot;Depth&quot;, &quot;Latitude&quot;, &quot;Longitude&quot;, &quot;YEAR&quot;, &quot;MeanBottomTemp_Cdeg&quot;, &quot;MeanBotSalinity_PSU&quot;, &quot;unified_ID&quot;)] hp_pca &lt;- pca_wrapper(hilic_pos, md, &quot;Hilic pos&quot;) hn_pca &lt;- pca_wrapper(hilic_neg, md, &quot;Hilic neg&quot;) rp_pca &lt;- pca_wrapper(rp_pos, md, &quot;RP pos&quot;) rn_pca &lt;- pca_wrapper(rp_neg, md, &quot;RP pos&quot;) multiplot(hp_pca, hn_pca, rp_pca, rn_pca, cols = 2) permanova(hilic_pos, md) permanova(hilic_neg, md) permanova(rp_pos, md) permanova(rp_neg, md) hp_opls_df &lt;- spl_ada(hilic_pos, md) hn_opls_df &lt;- spl_ada(hilic_neg, md) rp_opls_df &lt;- spl_ada(rp_pos, md) rn_opls_df &lt;- spl_ada(rp_neg, md) a &lt;- Sys.time() hp_cleaned_opls &lt;- ropls_wrapper(hp_opls_df, NA, 1, NA) hn_cleaned_opls &lt;- ropls_wrapper(hn_opls_df, NA, NA, NA) rp_cleaned_opls &lt;- ropls_wrapper(rp_opls_df, NA, 1, NA) rn_cleaned_opls &lt;- ropls_wrapper(rn_opls_df, 1, 1, NA) b &lt;- Sys.time() b - a ion &lt;- rbind(hp_cleaned_opls, hn_cleaned_opls, rp_cleaned_opls, rn_cleaned_opls) ion[&quot;Experiment&quot;] &lt;- c(rep(&quot;HILIC pos&quot;, 3), rep(&quot;HILIC neg&quot;, 3), rep(&quot;RP pos&quot;, 3), rep(&quot;RP neg&quot;, 3)) write.csv(ion, &quot;data/cleaned_MH_opls_diagnostics.csv&quot;, row.names = F) # load data PC_GROUP hilic_pos &lt;- read.csv(&quot;data/HILIC_pos_20190417_cleaned_pcgroup.csv&quot;, header = T, sep = &quot;,&quot;) hilic_neg &lt;- read.csv(&quot;data/HILIC_neg_20190421_cleaned_pcgroup.csv&quot;, header = T, sep = &quot;,&quot;) rp_pos &lt;- read.csv(&quot;data/RP_pos_20190421_cleaned_pcgroup.csv&quot;, header = T, sep = &quot;,&quot;) rp_neg &lt;- read.csv(&quot;data/RP_neg_20190422_cleaned_pcgroup.csv&quot;, header = T, sep = &quot;,&quot;) meta_data &lt;- read.csv(&quot;data/Steffen_et_al_metadata_PANGAEA.csv&quot;, header = T, sep = &quot;;&quot;) hilic_pos &lt;- formatting(hilic_pos, meta_data, 8, &quot;LC.MS.HILIC.positive&quot;) hilic_neg &lt;- formatting(hilic_neg, meta_data, 8, &quot;LC.MS.HILIC.negative&quot;) rp_pos &lt;- formatting(rp_pos, meta_data, 8, &quot;LC.MS.RP.positive&quot;) rp_neg &lt;- formatting(rp_neg, meta_data, 8, &quot;LC.MS.RP.negative&quot;) md &lt;- meta_data[, c(&quot;Species&quot;, &quot;Depth&quot;, &quot;Latitude&quot;, &quot;Longitude&quot;, &quot;YEAR&quot;, &quot;MeanBottomTemp_Cdeg&quot;, &quot;MeanBotSalinity_PSU&quot;, &quot;unified_ID&quot;)] hp_pca &lt;- pca_wrapper(hilic_pos, md, &quot;Hilic pos&quot;) hn_pca &lt;- pca_wrapper(hilic_neg, md, &quot;Hilic neg&quot;) rp_pca &lt;- pca_wrapper(rp_pos, md, &quot;RP pos&quot;) rn_pca &lt;- pca_wrapper(rp_neg, md, &quot;RP pos&quot;) multiplot(hp_pca, hn_pca, rp_pca, rn_pca, cols = 2) permanova(hilic_pos, md) permanova(hilic_neg, md) permanova(rp_pos, md) permanova(rp_neg, md) hp_opls_df &lt;- spl_ada(hilic_pos, md) hn_opls_df &lt;- spl_ada(hilic_neg, md) rp_opls_df &lt;- spl_ada(rp_pos, md) rn_opls_df &lt;- spl_ada(rp_neg, md) a &lt;- Sys.time() hp_cleaned_opls &lt;- ropls_wrapper(hp_opls_df, NA, NA, NA) hn_cleaned_opls &lt;- ropls_wrapper(hn_opls_df, NA, NA, NA) rp_cleaned_opls &lt;- ropls_wrapper(rp_opls_df, NA, NA, NA) rn_cleaned_opls &lt;- ropls_wrapper(rn_opls_df, NA, NA, NA) b &lt;- Sys.time() b - a pcg &lt;- rbind(hp_cleaned_opls, hn_cleaned_opls, rp_cleaned_opls, rn_cleaned_opls) pcg[&quot;Experiment&quot;] &lt;- c(rep(&quot;HILIC pos&quot;, 3), rep(&quot;HILIC neg&quot;, 3), rep(&quot;RP pos&quot;, 3), rep(&quot;RP neg&quot;, 3)) write.csv(pcg, &quot;data/cleaned_PC_opls_diagnostics.csv&quot;, row.names = F) The multivariate analyses were quite time consuming, requiring 1.4 hours for the “cleaned” data sets, 46.3 min for the “PC-group” data stes and 4 min for the “ion” data sets. The combined model diagnostics are summarised below. library(kableExtra) cleaned &lt;- read.csv(&quot;data/cleaned_opls_diagnostics.csv&quot;, header = T) pcgrp &lt;- read.csv(&quot;data/cleaned_PC_opls_diagnostics.csv&quot;, header = T) ion &lt;- read.csv(&quot;data/cleaned_MH_opls_diagnostics.csv&quot;, header = T) opls_diagnostics &lt;- rbind(cleaned, pcgrp, ion) opls_diagnostics[&quot;filtering&quot;] &lt;- c(rep(&quot;cleaned&quot;, 12), rep(&quot;pc group&quot;, 12), rep(&quot;ion&quot;, 12)) options(kableExtra.html.bsTable = T) kable(opls_diagnostics, col.names = c(&quot;R2X cum&quot;, &quot;R2Y cum&quot;, &quot;Q2 cum&quot;, &quot;RMSEE&quot;, &quot;pre&quot;, &quot;ort&quot;, &quot;pR2Y&quot;, &quot;pQ2&quot;, &quot;Species&quot;, &quot;Experiment&quot;, &quot;data set&quot;), longtable = T, booktabs = T, caption = &quot;Model diagnostics of the metabolome variations modelled by depth&quot;, row.names = FALSE) %&gt;% add_header_above(c(Diagnostics = 8, `Data set attribution` = 3)) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;bordered&quot;, &quot;condensed&quot;, &quot;responsive&quot;), font_size = 12, full_width = F, latex_options = c(&quot;striped&quot;, &quot;scale_down&quot;)) Table 2.1: Model diagnostics of the metabolome variations modelled by depth Diagnostics Data set attribution R2X cum R2Y cum Q2 cum RMSEE pre ort pR2Y pQ2 Species Experiment data set 0.425 0.998 0.8670 19.7 1 2 0.001 0.001 Geodia barretti HILIC pos cleaned 0.257 0.988 0.6530 42.0 1 1 0.067 0.002 Stryphnus fortis HILIC pos cleaned 0.496 0.999 0.5490 13.7 1 3 0.002 0.028 Weberella bursa HILIC pos cleaned 0.464 0.988 0.7670 47.4 1 2 0.010 0.001 Geodia barretti HILIC neg cleaned 0.436 0.924 0.6290 106.0 1 1 0.074 0.002 Stryphnus fortis HILIC neg cleaned 0.366 0.985 0.5560 42.4 1 2 0.233 0.013 Weberella bursa HILIC neg cleaned 0.585 0.998 0.7960 22.6 1 3 0.003 0.001 Geodia barretti RP pos cleaned 0.328 0.965 0.5680 71.5 1 1 0.039 0.010 Stryphnus fortis RP pos cleaned 0.343 0.980 0.3350 48.8 1 2 0.113 0.108 Weberella bursa RP pos cleaned 0.304 0.937 0.6140 99.8 1 1 0.040 0.003 Geodia barretti RP neg cleaned 0.390 0.924 0.5060 106.0 1 1 0.089 0.015 Stryphnus fortis RP neg cleaned 0.412 0.985 0.4500 41.9 1 2 0.029 0.027 Weberella bursa RP neg cleaned 0.429 0.997 0.8660 23.7 1 2 0.003 0.001 Geodia barretti HILIC pos pc group 0.362 0.998 0.7020 19.9 1 2 0.049 0.004 Stryphnus fortis HILIC pos pc group 0.542 0.995 0.5820 25.9 1 3 0.114 0.015 Weberella bursa HILIC pos pc group 0.499 0.990 0.7500 43.2 1 2 0.004 0.002 Geodia barretti HILIC neg pc group 0.433 0.990 0.7230 40.9 1 2 0.068 0.002 Stryphnus fortis HILIC neg pc group 0.390 0.986 0.6000 39.8 1 2 0.132 0.005 Weberella bursa HILIC neg pc group 0.602 0.996 0.8090 28.9 1 3 0.014 0.001 Geodia barretti RP pos pc group 0.464 0.990 0.5850 40.9 1 2 0.122 0.017 Stryphnus fortis RP pos pc group 0.393 0.979 0.3590 49.8 1 2 0.045 0.115 Weberella bursa RP pos pc group 0.373 0.979 0.6850 59.9 1 2 0.137 0.002 Geodia barretti RP neg pc group 0.637 0.991 0.6140 39.9 1 3 0.455 0.035 Stryphnus fortis RP neg pc group 0.440 0.980 0.4170 48.6 1 2 0.089 0.049 Weberella bursa RP neg pc group 0.761 0.995 0.6610 34.2 1 5 0.072 0.018 Geodia barretti HILIC pos ion 0.294 0.915 0.3540 112.0 1 1 0.226 0.109 Stryphnus fortis HILIC pos ion 0.694 0.988 0.6570 40.2 1 4 0.032 0.019 Weberella bursa HILIC pos ion 0.401 0.942 0.6580 105.0 1 2 0.013 0.002 Geodia barretti HILIC neg ion 0.815 0.992 0.7570 39.5 1 3 0.007 0.008 Stryphnus fortis HILIC neg ion 0.556 0.949 0.6530 77.3 1 2 0.005 0.004 Weberella bursa HILIC neg ion 0.778 0.910 0.7940 126.0 1 1 0.001 0.001 Geodia barretti RP pos ion 0.368 0.874 0.2560 137.0 1 1 0.026 0.159 Stryphnus fortis RP pos ion 0.479 0.960 0.4060 68.1 1 2 0.005 0.032 Weberella bursa RP pos ion 0.430 0.624 0.0345 244.0 1 1 0.268 0.198 Geodia barretti RP neg ion 0.821 0.392 0.0936 300.0 1 1 0.585 0.190 Stryphnus fortis RP neg ion 0.804 0.973 0.5850 61.8 1 4 0.065 0.027 Weberella bursa RP neg ion write.csv(opls_diagnostics, &quot;data/opls_diagnostics.csv&quot;, row.names = F) 2.4 VIPS??? 2.5 Manual annotation, identification and extraction of metabolic feature signals A manually curated data set of signal intensities was produced for analysis of identified known and novel compounds. library(ggplot2) library(ggrepel) library(reshape) library(tidyverse) library(forcats) cmp &lt;- read.csv(&quot;data/metabolite_master_20190605.csv&quot;, header = T, sep = &quot;,&quot;) meta_data &lt;- read.csv(&quot;data/Steffen_et_al_metadata_PANGAEA.csv&quot;, header = T, sep = &quot;;&quot;) md &lt;- md[c(&quot;Depth&quot;, &quot;unified_ID&quot;)] # FUN prep: remove, QC samples format depth and IDs prep &lt;- function(metabolites, md) { metabolites$X &lt;- NULL metabolites[&quot;spec&quot;] &lt;- str_sub(metabolites$unified_ID, 1, 2) metabolites &lt;- metabolites[!metabolites$spec == &quot;QC&quot;, ] metabolites &lt;- left_join(metabolites, md) metabolites &lt;- metabolites[-c(9), ] #removes Gb16 (Geodia atlantica) metabolites$Depth &lt;- as.numeric(metabolites$Depth) metabolites &lt;- metabolites[with(metabolites, order(metabolites$spec, metabolites$Depth)), ] metabolites[] &lt;- lapply(metabolites, function(x) if (is.factor(x)) factor(x) else x) metabolites$unified_ID &lt;- factor(metabolites$unified_ID, levels = metabolites$unified_ID) return(metabolites) } metabolites &lt;- prep(cmp, md) library(reshape2) mets &lt;- metabolites[, c(&quot;asb&quot;, &quot;his&quot;, &quot;cre&quot;, &quot;pch&quot;, &quot;crn&quot;, &quot;acl&quot;, &quot;ser&quot;, &quot;mbc&quot;, &quot;chol_s&quot;, &quot;bet&quot;, &quot;choline&quot;, &quot;ura&quot;, &quot;unified_ID&quot;, &quot;spec&quot;, &quot;Depth&quot;)] colnames(mets) &lt;- c(&quot;arseno- betaine&quot;, &quot;histamine&quot;, &quot;creatine&quot;, &quot;phospho- choline&quot;, &quot;carnitine&quot;, &quot;acetyl- choline&quot;, &quot;serotonin&quot;, &quot;2-methyl- butyroyl- carnitine&quot;, &quot;choline sulfate&quot;, &quot;betaine&quot;, &quot;choline&quot;, &quot;uranidine&quot;, &quot;unified_ID&quot;, &quot;spec&quot;, &quot;Depth&quot;) mets &lt;- melt(mets, id.vars = c(&quot;spec&quot;, &quot;Depth&quot;, &quot;unified_ID&quot;)) mets[&quot;Species&quot;] &lt;- NA mets$Species[mets$spec == &quot;Gb&quot;] &lt;- c(&quot;Geodia barretti&quot;) mets$Species[mets$spec == &quot;Sf&quot;] &lt;- c(&quot;Stryphnus fortis&quot;) mets$Species[mets$spec == &quot;Wb&quot;] &lt;- c(&quot;Weberella bursa&quot;) # labeller needs formula interface all &lt;- ggplot(mets, aes(x = Depth, y = value)) + geom_point() + facet_grid(variable ~ Species, labeller = labeller(variable = label_wrap_gen(10, multi_line = TRUE)), scales = &quot;free&quot;) all &lt;- all + ggtitle(&quot;VIPs&quot;) + ylab(&quot;signal&quot;) + xlab(&quot;Depth&quot;) + theme_bw() + theme(strip.text.x = element_text(face = &quot;italic&quot;), panel.background = element_rect(fill = &quot;white&quot;, colour = &quot;black&quot;), panel.border = element_rect(colour = &quot;black&quot;, fill = NA), axis.text.x = element_text(angle = 90, hjust = 1)) + scale_y_continuous(labels = scales::scientific) + scale_x_continuous(breaks = scales::pretty_breaks(n = 12)) all 2.6 Correlations sessionInfo() ## R version 3.5.1 (2018-07-02) ## Platform: x86_64-apple-darwin15.6.0 (64-bit) ## Running under: macOS 10.14.6 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] grid stats graphics grDevices utils datasets methods ## [8] base ## ## other attached packages: ## [1] reshape_0.8.8 ggrepel_0.8.2 vegan_2.5-6 ## [4] lattice_0.20-41 permute_0.9-5 forcats_0.5.0 ## [7] purrr_0.3.3 readr_1.3.1 tidyr_1.0.2 ## [10] tibble_3.0.0 tidyverse_1.3.0 ropls_1.14.1 ## [13] reshape2_1.4.3 kableExtra_1.1.0.9000 ggplot2_3.3.0 ## [16] stringr_1.4.0 dplyr_0.8.5 knitr_1.28 ## ## loaded via a namespace (and not attached): ## [1] Rcpp_1.0.4 lubridate_1.7.4 assertthat_0.2.1 ## [4] digest_0.6.25 cellranger_1.1.0 R6_2.4.1 ## [7] plyr_1.8.6 backports_1.1.5 reprex_0.3.0 ## [10] evaluate_0.14 httr_1.4.1 highr_0.8 ## [13] pillar_1.4.3 rlang_0.4.5 readxl_1.3.1 ## [16] rstudioapi_0.11 Matrix_1.2-18 rmarkdown_2.1 ## [19] labeling_0.3 splines_3.5.1 webshot_0.5.2 ## [22] munsell_0.5.0 broom_0.5.5 compiler_3.5.1 ## [25] modelr_0.1.6 xfun_0.12 pkgconfig_2.0.3 ## [28] BiocGenerics_0.28.0 mgcv_1.8-31 htmltools_0.4.0 ## [31] tidyselect_1.0.0 bookdown_0.18 fansi_0.4.1 ## [34] viridisLite_0.3.0 crayon_1.3.4 dbplyr_1.4.2 ## [37] withr_2.1.2 MASS_7.3-51.5 nlme_3.1-145 ## [40] jsonlite_1.6.1 gtable_0.3.0 lifecycle_0.2.0 ## [43] DBI_1.1.0 magrittr_1.5 formatR_1.7 ## [46] scales_1.1.0 cli_2.0.2 stringi_1.4.6 ## [49] farver_2.0.3 fs_1.4.0 xml2_1.3.0 ## [52] ellipsis_0.3.0 vctrs_0.2.4 generics_0.0.2 ## [55] tools_3.5.1 Biobase_2.42.0 glue_1.3.2 ## [58] hms_0.5.3 parallel_3.5.1 yaml_2.2.1 ## [61] colorspace_1.4-1 cluster_2.1.0 rvest_0.3.5 ## [64] haven_2.2.0 "]
]
