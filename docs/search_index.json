[
["metabolomics.html", "2 Metabolomics 2.1 Experimental methods and detailed description 2.2 Data processing 2.3 Multivariate analyses 2.4 Manual annotation, identification and extraction of metabolic feature signals 2.5 Correlations", " 2 Metabolomics 2.1 Experimental methods and detailed description Additional sampling notes During the sampling on the Pâmiut cruises, the sponges remained on deck or in the laboratory for approximately 30–45 min before they were frozen to -20°C. The outside temperature usually oscillated around 4–5°C, and the sorting area was approximately 10°C. The sample consisted of both choanosome and coretx. Laboratory methods and data acquisition Metabolites were separated in connection to downstream mass spectrometry (HRMS) analysis using two different chromatographic columns (UPLC): a hydrophilic interaction liquid chromatography (HILIC) column that retains polar compounds, and a reversed-phase (RP) column that favours retention of non-polar compounds. All samples were processed in randomized order using glass instruments during the extraction to avoid chemical contamination. Mass spectrometry analysis Dried extracts in glass vials were dissolved in 200 µL solvent (HILIC: 50 µL H2O and 175 µL acetonitrile AcN; RP: 140 µL H2O and 10 µL AcN). Upon addition of the organic solvent for HILIC chromatography, all samples separated into two immiscible layers. The vials were centrifuged for 3 min at 2000 x g to yield an even separation. Only the top layer (approximately 150 µL) was transferred to a Chromacol 03-FISV MS-vial (Thermo Scientific, Waltham, Massachusetts, USA) for MS analyses. For RP chromatography, no layers were observed, and the entire volume of the dissolved sample was used. A five µL aliquot from each individual MS-vial for HILIC and RP, respectively, was combined to produce a quality control (QC) sample. High resolution MS analysis system and settings The extracts were analyzed back-to-back in positive and negative ionization mode on an Acquity I-Class Ultra Performance Liquid Chromatography UPLC coupled to a G2S Synapt Q-TOF with an electrospray ionization (ESI) ion source (all Waters Corp., Milford, MA, USA). Chromatographic separation in HILIC mode was performed on an Acquity UPLC BEH Amide column (1.7 µm, 2.1 mm inner diameter × 50 mm, Waters Corp.). Mobile phase A consisted of 95:5 acetonitrile/MQ water with 5 mM ammonium formate and 0.1 % formic acid (FA), and mobile phase B consisted of 40:60 acetonitrile/MQ water with 5 mM ammonium formate and 0.1 % FA. The gradient elution profile was as follows: mobile phase A was decreased non-linearly (slope factor 8, MassLynx) from 100 % A to 100 % B over 14 min, 100 % B was held for 2 min and then decreased back to 100 % A over 1 min. The column was re-equilibrated at 100 % A for 6 min for a total runtime of 23 min. Chromatographic separation in RP was performed on an Acquity UPLC BEH C18 column (1.7 µ m, 2.1 mm inner diameter × 50 mm, Waters). Mobile phase A consisted of MQ water with 0.1 % FA, and mobile phase B was AcN with 0.1 % FA. The gradient elution profile started at 95 % A, was decreased linearly over 14 min to 5 % A, and 5 % A was held for 2 min before the column was re-equilibrated at 95 % A for 4 min. The flow rate was set to 0.4 mL/min, the column temperature was set to 40°C, the samples were kept at 8°C and the injection volume was 5 µL in all experiments. Data acquisition Data acquisition was performed using MSE mode, and lock mass correction was applied using a solution of leucine enkephalin in both positive and negative mode. Ionization parameters were set as follows in positive/negative mode; the capillary voltage was 1kV/1.5 kV, the cone voltage was 30 V/25 V, the source offset was 50/60 and the source temperature was set to 120°C. Nitrogen was used as desolvation and cone gas with gas flows of 800 l/h and 50 l/h, respectively, and desolvation temperature was set to 500°C/450°C. For MSE acquisition a collision energy ramp from 20–45 eV was used with argon as collision gas. The instrument was calibrated in the m/z range 50–1500 using sodium formate prior to each analysis. All study samples were analysed in both RP and HILIC, in positive and negative ionization mode, resulting in four metabolite datasets per sponge specimen. The column and sample cone was cleaned in between each analysis mode. Prior to each analysis ten QC injections were made to condition the column, and to ensure stable retention times and signal intensities. The study samples were analysed in randomized order with QC injections interspaced every 6th injection. MS data processing Raw files were converted to netCDF files by Databridge (part of MassLynx, Waters Corporation, Milford, Massachusetts, USA). The netCDF files with the chromatographic spectra were sorted into folders according to species and processed with XCMS in R. Peak picking was performed using the centWave function with parameters ppm=8, peakwidth set to c(5,45) and the noise parameter set to 2000. Retention time alignment was performed with the obiwarp function and the response factor set to 10, grouping was performed with the “group” function and the “fillPeaks” function was used to impute a signal in cases where no matching pseudospectra were detected. The data set was curated to remove features eluting in the void (retention time less than 45 s). A raw data set as well as two normalized data sets (Log10-transformed and median fold change normalized) were produced and filtered to only retain features with a coefficient of variation &lt; 30% in the QC samples. After subsequent evaluation, raw data sets were used in subsequent statistics and modelling. An overview of the number of features and PC groups annotated by CAMERA, as well as their exclusion is given in a table at the end of this document. 2.2 Data processing 2.2.1 Peak picking with XCMS and annotation with CAMERA We processed samples from all three sponnge species in random order with interspersed injection of a combined QC sample to monitor stability of the UPLC-HRMS run. The acquired signals/spectra were convered to netCDF format using the Program DataBridge, and thereafter sorted into four folders, three for the sponge species (Gb, Sf, Wb) and one for the QC samples (QC). Peak picking and combination of pseudospectra is performed with the R package xcms, the subsequent annotation of adducts and isotopes with the R package CAMERA. 2.2.2 HILIC (Hydrophilic interaction chromatography) column with positive ESI (electron spray ionisation) # HILIC POS ALWAYS CHECK DATE, CHROMATOGRAPHIC CLOUMN (HILIC, RP) AND ESI-MODE # (naming, CAMERA: pos, neg) # setwd() # work in directory containing the sorted CDF files. getwd() library(xcms) xset &lt;- xcmsSet(method = &quot;centWave&quot;, ppm = 8, peakwidth = c(5, 45), noise = 2000) save(xset, file = &quot;HILIC_pos_xset_20190417.Rda&quot;) # load(file=&#39;HILIC_pos_xset_20190417.Rda&#39;) #When resuming after a break xset &lt;- group(xset) xset2 &lt;- retcor(xset, method = &quot;obiwarp&quot;, response = 10, plottype = &quot;deviation&quot;) xset2 &lt;- group(xset2) xset3 &lt;- fillPeaks(xset2) save(xset3, file = &quot;HILIC_pos_xset3_20190417.Rda&quot;) reporttab &lt;- diffreport(xset3, &quot;Gb&quot;, &quot;Sf&quot;, &quot;Gb_Sf_HILIC_pos_20190417&quot;, 10) library(CAMERA) xsa &lt;- xsAnnotate(xset3) xsaF &lt;- groupFWHM(xsa, perfwhm = 0.3) xsaC &lt;- groupCorr(xsaF, cor_eic_th = 0.7) xsaFI &lt;- findIsotopes(xsaC) rules &lt;- read.csv(&quot;data/rules_jan_pos.csv&quot;, header = T, sep = &quot;,&quot;) xsaFA &lt;- findAdducts(xsaFI, polarity = &quot;positive&quot;, rules = rules) # write.csv(getPeaklist(xsaFA), file=&#39;HILIC_pos_20190417.csv&#39;) The other data experiments, HILIC with negative ESI and RP with positive and negative ESI are processed accordingly. 2.2.3 HILIC Chromatography with negative ESI # HILIC NEG 20190421 # setwd() # work in directory containing the sorted CDF files. getwd() library(xcms) xset &lt;- xcmsSet(method = &quot;centWave&quot;, ppm = 8, peakwidth = c(5, 45), noise = 2000) save(xset, file = &quot;HILIC_neg_xset_20190421.Rda&quot;) # load(file=&#39;HILIC_neg_xset_20190421.Rda&#39;) #When resuming after a break xset &lt;- group(xset) xset2 &lt;- retcor(xset, method = &quot;obiwarp&quot;, response = 10, plottype = &quot;deviation&quot;) xset2 &lt;- group(xset2) xset3 &lt;- fillPeaks(xset2) save(xset3, file = &quot;HILIC_neg_xset3_20190421.Rda&quot;) reporttab &lt;- diffreport(xset3, &quot;Gb&quot;, &quot;Sf&quot;, &quot;Gb_Sf_HILIC_neg_20190421&quot;, 10) library(CAMERA) xsa &lt;- xsAnnotate(xset3) xsaF &lt;- groupFWHM(xsa, perfwhm = 0.3) xsaC &lt;- groupCorr(xsaF, cor_eic_th = 0.7) xsaFI &lt;- findIsotopes(xsaC) rules &lt;- read.csv(&quot;data/rules_jan_neg.csv&quot;, header = T, sep = &quot;,&quot;) xsaFA &lt;- findAdducts(xsaFI, polarity = &quot;negative&quot;, rules = rules) # write.csv(getPeaklist(xsaFA), file=&#39;HILIC_neg_20190421.csv&#39;) 2.2.4 RP (Reversed phase) Chromatography with positive ESI # RP POS 20190421 # setwd() # work in directory containing the sorted CDF files. getwd() library(xcms) xset &lt;- xcmsSet(method = &quot;centWave&quot;, ppm = 8, peakwidth = c(5, 45), noise = 2000) save(xset, file = &quot;RP_pos_xset_20190421.Rda&quot;) # load(file=&#39;RP_pos_xset_20190421.Rda&#39;) #When resuming after a break xset &lt;- group(xset) xset2 &lt;- retcor(xset, method = &quot;obiwarp&quot;, response = 10, plottype = &quot;deviation&quot;) xset2 &lt;- group(xset2) xset3 &lt;- fillPeaks(xset2) save(xset3, file = &quot;RP_pos_xset3_20190421.Rda&quot;) reporttab &lt;- diffreport(xset3, &quot;Gb&quot;, &quot;Sf&quot;, &quot;Gb_Sf_RP_pos_20190421&quot;, 10) library(CAMERA) xsa &lt;- xsAnnotate(xset3) xsaF &lt;- groupFWHM(xsa, perfwhm = 0.3) xsaC &lt;- groupCorr(xsaF, cor_eic_th = 0.7) xsaFI &lt;- findIsotopes(xsaC) rules &lt;- read.csv(&quot;data/rules_jan_pos.csv&quot;, header = T, sep = &quot;,&quot;) xsaFA &lt;- findAdducts(xsaFI, polarity = &quot;positive&quot;, rules = rules) # write.csv(getPeaklist(xsaFA), file=&#39;RP_pos_20190421.csv&#39;) 2.2.5 RP Chromatography with negative ESI # RP NEG 20190422 # setwd() # work in directory containing the sorted CDF files. getwd() library(xcms) xset &lt;- xcmsSet(method = &quot;centWave&quot;, ppm = 8, peakwidth = c(5, 45), noise = 2000) save(xset, file = &quot;RP_neg_xset_20190422.Rda&quot;) # load(file=&#39;RP_neg_xset_20190422.Rda&#39;) #When resuming after a break xset &lt;- group(xset) xset2 &lt;- retcor(xset, method = &quot;obiwarp&quot;, response = 10, plottype = &quot;deviation&quot;) xset2 &lt;- group(xset2) xset3 &lt;- fillPeaks(xset2) save(xset3, file = &quot;RP_neg_xset3_20190422.Rda&quot;) reporttab &lt;- diffreport(xset3, &quot;Gb&quot;, &quot;Sf&quot;, &quot;Gb_Sf_RP_neg_20190422&quot;, 10) library(CAMERA) xsa &lt;- xsAnnotate(xset3) xsaF &lt;- groupFWHM(xsa, perfwhm = 0.3) xsaC &lt;- groupCorr(xsaF, cor_eic_th = 0.7) xsaFI &lt;- findIsotopes(xsaC) rules &lt;- read.csv(&quot;data/rules_jan_neg.csv&quot;, header = T, sep = &quot;,&quot;) xsaFA &lt;- findAdducts(xsaFI, polarity = &quot;negative&quot;, rules = rules) # write.csv(getPeaklist(xsaFA), file=&#39;RP_neg_20190422.csv&#39;) 2.2.6 Filtering of the raw data set Features with with following properties were removed: Eluting in the void (RT &lt; 45 s) CV&gt;30 % in QC samples Adducts as annotated by CAMERA As the presence of the same parent feature in the the form of isotopes and adducts distorts downstream global metabolome analyses, we generated two versions of curated or selective feature tables. In both, void and unstably measured features are removed (“cleaned”). One retains only the feature with the largest signal per pc group (“cleaned_pcgroup”), the other is more stringent and only contains explicitly annotated parent ions (“cleaned_MH”), i.e. [M+H]+ for positive ESI and [M-H]- for negative ESI acquired data. library(dplyr) # ================================ HILIC pos =================================== raw_peaks &lt;- read.csv(&quot;data/HILIC_pos_20190417.csv&quot;) hp_dim1 &lt;- dim(raw_peaks)[1] hp_pcg1 &lt;- length(unique(raw_peaks$pcgroup)) # Removing features eluting in the void raw_peaks &lt;- raw_peaks[raw_peaks$rt &gt; 45, ] hp_dim2 &lt;- dim(raw_peaks)[1] hp_pcg2 &lt;- length(unique(raw_peaks$pcgroup)) # Removing features with a CV &lt; 30% f &lt;- which(colnames(raw_peaks) == &quot;IE_20170918_02001&quot;) # first QC HILIC pos l &lt;- which(colnames(raw_peaks) == &quot;IE_20170918_07601&quot;) # last QC HILIC pos raw_peaks[&quot;SD&quot;] &lt;- apply(raw_peaks[, f:l], 1, sd) raw_peaks[&quot;MEAN&quot;] &lt;- apply(raw_peaks[, f:l], 1, mean) raw_peaks[&quot;CV&quot;] &lt;- raw_peaks$SD/raw_peaks$MEAN raw_peaks &lt;- raw_peaks[raw_peaks$CV &lt; 0.3, ] hp_dim3 &lt;- dim(raw_peaks)[1] hp_pcg3 &lt;- length(unique(raw_peaks$pcgroup)) # write.csv(raw_peaks, &#39;HILIC_pos_20190417_cleaned.csv&#39;) # Keep only the feature with the greatest sum of signal per pc group l &lt;- dim(raw_peaks)[2] - 6 raw_peaks[&quot;fss&quot;] &lt;- apply(raw_peaks[, 13:l], 1, sum) #feature signal sum raw_peaks &lt;- raw_peaks[order(raw_peaks$pcgroup, -raw_peaks$fss), ] # for every pc group, the first line has the strongest signal. The function # distinct() [dplyr package] can be used to keep only unique/distinct rows from a # data frame. If there are duplicate rows, _only the first row_ is preserved. selected_peaks &lt;- distinct(raw_peaks, raw_peaks$pcgroup, .keep_all = TRUE) hp_dim4 &lt;- dim(selected_peaks)[1] hp_pcg4 &lt;- length(unique(selected_peaks$pcgroup)) # write.csv(selected_peaks, &#39;HILIC_pos_20190417_cleaned_pcgroup.csv&#39;) rm(selected_peaks) # Keep only features with explicit annotations of [M+H]+ library(stringr) raw_peaks[&quot;[M+H]+&quot;] &lt;- NA pattern &lt;- &quot;[M+H]+&quot; raw_peaks[&quot;[M+H]+&quot;] &lt;- str_detect(raw_peaks$adduct, paste0(&quot;^\\\\Q&quot;, pattern, &quot;\\\\E&quot;)) selected_peaks &lt;- raw_peaks[raw_peaks$`[M+H]+` == &quot;TRUE&quot;, ] hp_dim5 &lt;- dim(selected_peaks)[1] hp_pcg5 &lt;- length(unique(selected_peaks$pcgroup)) # write.csv(selected_peaks, &#39;HILIC_pos_20190417_cleaned_MH.csv&#39;) hilic_pos &lt;- raw_peaks rm(f, l, raw_peaks, selected_peaks) # ================================ HILIC neg =================================== raw_peaks &lt;- read.csv(&quot;data/HILIC_neg_20190421.csv&quot;) hn_dim1 &lt;- dim(raw_peaks)[1] hn_pcg1 &lt;- length(unique(raw_peaks$pcgroup)) # Removing features eluting in the void raw_peaks &lt;- raw_peaks[raw_peaks$rt &gt; 45, ] hn_dim2 &lt;- dim(raw_peaks)[1] hn_pcg2 &lt;- length(unique(raw_peaks$pcgroup)) # Removing features with a CV &lt; 30% f &lt;- which(colnames(raw_peaks) == &quot;IE_20170919_01301&quot;) # first QC HILIC neg l &lt;- which(colnames(raw_peaks) == &quot;IE_20170919_06901&quot;) # last QC HILIC neg raw_peaks[&quot;SD&quot;] &lt;- apply(raw_peaks[, f:l], 1, sd) raw_peaks[&quot;MEAN&quot;] &lt;- apply(raw_peaks[, f:l], 1, mean) raw_peaks[&quot;CV&quot;] &lt;- raw_peaks$SD/raw_peaks$MEAN raw_peaks &lt;- raw_peaks[raw_peaks$CV &lt; 0.3, ] hn_dim3 &lt;- dim(raw_peaks)[1] hn_pcg3 &lt;- length(unique(raw_peaks$pcgroup)) # write.csv(raw_peaks, &#39;HILIC_neg_20190421_cleaned.csv&#39;) # Keep only the feature with the greatest sum of signal per pc group l &lt;- dim(raw_peaks)[2] - 6 raw_peaks[&quot;fss&quot;] &lt;- apply(raw_peaks[, 13:l], 1, sum) #feature signal sum raw_peaks &lt;- raw_peaks[order(raw_peaks$pcgroup, -raw_peaks$fss), ] selected_peaks &lt;- distinct(raw_peaks, raw_peaks$pcgroup, .keep_all = TRUE) hn_dim4 &lt;- dim(selected_peaks)[1] hn_pcg4 &lt;- length(unique(selected_peaks$pcgroup)) # write.csv(selected_peaks, &#39;HILIC_neg_20190421_cleaned_pcgroup.csv&#39;) rm(selected_peaks) # Keep only features with explicit annotations of [M-H]- library(stringr) raw_peaks[&quot;[M-H]-&quot;] &lt;- NA pattern &lt;- &quot;[M-H]-&quot; raw_peaks[&quot;[M-H]-&quot;] &lt;- str_detect(raw_peaks$adduct, paste0(&quot;^\\\\Q&quot;, pattern, &quot;\\\\E&quot;)) selected_peaks &lt;- raw_peaks[raw_peaks$`[M-H]-` == &quot;TRUE&quot;, ] hn_dim5 &lt;- dim(selected_peaks)[1] hn_pcg5 &lt;- length(unique(selected_peaks$pcgroup)) # write.csv(selected_peaks, &#39;HILIC_neg_20190421_cleaned_MH.csv&#39;) hilic_neg &lt;- raw_peaks rm(f, l, raw_peaks) # ================================== RP pos ==================================== raw_peaks &lt;- read.csv(&quot;data/RP_pos_20190421.csv&quot;) rp_dim1 &lt;- dim(raw_peaks)[1] rp_pcg1 &lt;- length(unique(raw_peaks$pcgroup)) # Removing features eluting in the void raw_peaks &lt;- raw_peaks[raw_peaks$rt &gt; 45, ] rp_dim2 &lt;- dim(raw_peaks)[1] rp_pcg2 &lt;- length(unique(raw_peaks$pcgroup)) # Removing features with a CV &lt; 30% f &lt;- which(colnames(raw_peaks) == &quot;IE_20171002_01401&quot;) # first QC RP neg l &lt;- which(colnames(raw_peaks) == &quot;IE_20171002_07201&quot;) # last QC RP neg raw_peaks[&quot;SD&quot;] &lt;- apply(raw_peaks[, f:l], 1, sd) raw_peaks[&quot;MEAN&quot;] &lt;- apply(raw_peaks[, f:l], 1, mean) raw_peaks[&quot;CV&quot;] &lt;- raw_peaks$SD/raw_peaks$MEAN raw_peaks &lt;- raw_peaks[raw_peaks$CV &lt; 0.3, ] rp_dim3 &lt;- dim(raw_peaks)[1] rp_pcg3 &lt;- length(unique(raw_peaks$pcgroup)) # write.csv(raw_peaks, &#39;RP_pos_20190421_cleaned.csv&#39;) # Keep only the feature with the greatest sum of signal per pc group l &lt;- dim(raw_peaks)[2] - 6 raw_peaks[&quot;fss&quot;] &lt;- apply(raw_peaks[, 13:l], 1, sum) #feature signal sum raw_peaks &lt;- raw_peaks[order(raw_peaks$pcgroup, -raw_peaks$fss), ] selected_peaks &lt;- distinct(raw_peaks, raw_peaks$pcgroup, .keep_all = TRUE) rp_dim4 &lt;- dim(selected_peaks)[1] rp_pcg4 &lt;- length(unique(selected_peaks$pcgroup)) # write.csv(selected_peaks, &#39;RP_pos_20190421_cleaned_pcgroup.csv&#39;) rm(selected_peaks) # Keep only features with explicit annotations of [M+H]+ library(stringr) raw_peaks[&quot;[M+H]+&quot;] &lt;- NA pattern &lt;- &quot;[M+H]+&quot; raw_peaks[&quot;[M+H]+&quot;] &lt;- str_detect(raw_peaks$adduct, paste0(&quot;^\\\\Q&quot;, pattern, &quot;\\\\E&quot;)) selected_peaks &lt;- raw_peaks[raw_peaks$`[M+H]+` == &quot;TRUE&quot;, ] rp_dim5 &lt;- dim(selected_peaks)[1] rp_pcg5 &lt;- length(unique(selected_peaks$pcgroup)) # write.csv(selected_peaks, &#39;RP_pos_20190421_cleaned_MH.csv&#39;) rp_pos &lt;- raw_peaks rm(f, l, raw_peaks, selected_peaks) # ================================== RP neg ==================================== raw_peaks &lt;- read.csv(&quot;data/RP_neg_20190422.csv&quot;) rn_dim1 &lt;- dim(raw_peaks)[1] rn_pcg1 &lt;- length(unique(raw_peaks$pcgroup)) # Removing features eluting in the void raw_peaks &lt;- raw_peaks[raw_peaks$rt &gt; 45, ] rn_dim2 &lt;- dim(raw_peaks)[1] rn_pcg2 &lt;- length(unique(raw_peaks$pcgroup)) # Removing features with a CV &lt; 30% f &lt;- which(colnames(raw_peaks) == &quot;IE_20171003_01301&quot;) # first QC RP neg l &lt;- which(colnames(raw_peaks) == &quot;IE_20171003_05701&quot;) # 3rd last QC RP neg; QC empty after this injection raw_peaks[&quot;SD&quot;] &lt;- apply(raw_peaks[, f:l], 1, sd) raw_peaks[&quot;MEAN&quot;] &lt;- apply(raw_peaks[, f:l], 1, mean) raw_peaks[&quot;CV&quot;] &lt;- raw_peaks$SD/raw_peaks$MEAN raw_peaks &lt;- raw_peaks[raw_peaks$CV &lt; 0.3, ] rn_dim3 &lt;- dim(raw_peaks)[1] rn_pcg3 &lt;- length(unique(raw_peaks$pcgroup)) # write.csv(raw_peaks, &#39;RP_neg_20190422_cleaned.csv&#39;) # Keep only the feature with the greatest sum of signal per pc group l &lt;- dim(raw_peaks)[2] - 6 raw_peaks[&quot;fss&quot;] &lt;- apply(raw_peaks[, 13:l], 1, sum) #feature signal sum raw_peaks &lt;- raw_peaks[order(raw_peaks$pcgroup, -raw_peaks$fss), ] selected_peaks &lt;- distinct(raw_peaks, raw_peaks$pcgroup, .keep_all = TRUE) rn_dim4 &lt;- dim(selected_peaks)[1] rn_pcg4 &lt;- length(unique(selected_peaks$pcgroup)) # write.csv(selected_peaks, &#39;RP_neg_20190422_cleaned_pcgroup.csv&#39;) rm(selected_peaks) # Keep only features with explicit annotations of [M-H]- library(stringr) raw_peaks[&quot;[M-H]-&quot;] &lt;- NA pattern &lt;- &quot;[M-H]-&quot; raw_peaks[&quot;[M-H]-&quot;] &lt;- str_detect(raw_peaks$adduct, paste0(&quot;^\\\\Q&quot;, pattern, &quot;\\\\E&quot;)) selected_peaks &lt;- raw_peaks[raw_peaks$`[M-H]-` == &quot;TRUE&quot;, ] rn_dim5 &lt;- dim(selected_peaks)[1] rn_pcg5 &lt;- length(unique(selected_peaks$pcgroup)) # write.csv(selected_peaks, &#39;RP_neg_20190422_cleaned_MH.csv&#39;) hilic_neg &lt;- raw_peaks rm(f, l, raw_peaks, selected_peaks) 2.2.7 Data quality control To monitor the stability of the signal during the UPLC-HRMS run, we plot the total signal per sample by injection order. hp &lt;- read.csv(&quot;data/HILIC_pos_20190417.csv&quot;, header = T, sep = &quot;,&quot;) hn &lt;- read.csv(&quot;data/HILIC_neg_20190421.csv&quot;, header = T, sep = &quot;,&quot;) rp &lt;- read.csv(&quot;data/RP_pos_20190421.csv&quot;, header = T, sep = &quot;,&quot;) rn &lt;- read.csv(&quot;data/RP_neg_20190422.csv&quot;, header = T, sep = &quot;,&quot;) # subsetting, keep only sample data hp &lt;- hp[, 13:(dim(hp)[2] - 3)] #14 hn &lt;- hn[, 13:(dim(hn)[2] - 3)] rp &lt;- rp[, 13:(dim(rp)[2] - 3)] rn &lt;- rn[, 13:(dim(rn)[2] - 3)] # sum signal of columns, i.e. per sample hp[nrow(hp) + 1, ] &lt;- apply(hp, 2, sum) hn[nrow(hn) + 1, ] &lt;- apply(hn, 2, sum) rp[nrow(rp) + 1, ] &lt;- apply(rp, 2, sum) rn[nrow(rn) + 1, ] &lt;- apply(rn, 2, sum) # data frame gymnastics hp_df &lt;- data.frame(t((hp[dim(hp)[1], ]))) hn_df &lt;- data.frame(t((hn[dim(hn)[1], ]))) rp_df &lt;- data.frame(t((rp[dim(rp)[1], ]))) rn_df &lt;- data.frame(t((rn[dim(rn)[1], ]))) colnames(hp_df) &lt;- c(&quot;colsum_hp&quot;) hp_df[&quot;id&quot;] &lt;- rownames(hp_df) colnames(hn_df) &lt;- c(&quot;colsum_hn&quot;) hn_df[&quot;id&quot;] &lt;- rownames(hn_df) colnames(rp_df) &lt;- c(&quot;colsum_rp&quot;) rp_df[&quot;id&quot;] &lt;- rownames(rp_df) colnames(rn_df) &lt;- c(&quot;colsum_rn&quot;) rn_df[&quot;id&quot;] &lt;- rownames(rn_df) library(stringr) hp_df[&quot;hp_io&quot;] &lt;- as.integer(str_sub(hp_df$id, -4, -3)) hn_df[&quot;hn_io&quot;] &lt;- as.integer(str_sub(hn_df$id, -4, -3)) rp_df[&quot;rp_io&quot;] &lt;- as.integer(str_sub(rp_df$id, -4, -3)) rn_df[&quot;rn_io&quot;] &lt;- as.integer(str_sub(rn_df$id, -4, -3)) hp_df &lt;- hp_df[order(hp_df$hp_io), ] hp_df[&quot;n&quot;] &lt;- seq(nrow(hp_df)) hp_df[&quot;experiment&quot;] &lt;- &quot;HILIC pos.&quot; hn_df &lt;- hn_df[order(hn_df$hn_io), ] hn_df[&quot;n&quot;] &lt;- seq(nrow(hn_df)) hn_df[&quot;experiment&quot;] &lt;- &quot;HILIC neg.&quot; rp_df &lt;- rp_df[order(rp_df$rp_io), ] rp_df[&quot;n&quot;] &lt;- seq(nrow(rp_df)) rp_df[&quot;experiment&quot;] &lt;- &quot;RP pos.&quot; rn_df &lt;- rn_df[order(rn_df$rn_io), ] rn_df[&quot;n&quot;] &lt;- seq(nrow(rn_df)) rn_df[&quot;experiment&quot;] &lt;- &quot;RP neg.&quot; colnames(hp_df) &lt;- c(&quot;colsum&quot;, &quot;id&quot;, &quot;io&quot;, &quot;n&quot;, &quot;experiment&quot;) colnames(hn_df) &lt;- c(&quot;colsum&quot;, &quot;id&quot;, &quot;io&quot;, &quot;n&quot;, &quot;experiment&quot;) colnames(rp_df) &lt;- c(&quot;colsum&quot;, &quot;id&quot;, &quot;io&quot;, &quot;n&quot;, &quot;experiment&quot;) colnames(rn_df) &lt;- c(&quot;colsum&quot;, &quot;id&quot;, &quot;io&quot;, &quot;n&quot;, &quot;experiment&quot;) stability &lt;- rbind(hp_df, hn_df, rp_df, rn_df) library(ggplot2) ggplot(stability, aes(x = n, y = colsum, color = experiment)) + geom_line(size = 1.5) + ggtitle(&quot;Signal intensity during UPLC-HRMS experiments&quot;) + xlab(&quot;sample injection order&quot;) + ylab(&quot;total signal intensity per sample&quot;) + labs(colour = &quot;Experiment&quot;) + theme(legend.position = &quot;bottom&quot;) + geom_smooth(method = &quot;lm&quot;, size = 0.5) + facet_grid(experiment ~ ., scales = &quot;free&quot;) rm(hp, hp_df, hn, hn_df, rp, rp_df, rn, rn_df, stability) 2.2.8 Summary of data processing Below we outline the number of features removed in every step as shown in the table and corresponding figure. initial_f &lt;- c(hp_dim1, hn_dim1, rp_dim1, rn_dim1) rt_f &lt;- c(hp_dim2, hn_dim2, rp_dim2, rn_dim2) cv_f &lt;- c(hp_dim3, hn_dim3, rp_dim3, rn_dim3) representative_f &lt;- c(hp_dim4, hn_dim4, rp_dim4, rn_dim4) ion_f &lt;- c(hp_dim5, hn_dim5, rp_dim5, rn_dim5) initial_p &lt;- c(hp_pcg1, hn_pcg1, rp_pcg1, rn_pcg1) rt_p &lt;- c(hp_pcg2, hn_pcg2, rp_pcg2, rn_pcg2) cv_p &lt;- c(hp_pcg3, hn_pcg3, rp_pcg3, rn_pcg3) representative_p &lt;- c(hp_pcg4, hn_pcg4, rp_pcg4, rn_pcg4) ion_p &lt;- c(hp_pcg5, hn_pcg5, rp_pcg5, rn_pcg5) df &lt;- cbind(initial_f, rt_f, cv_f, representative_f, ion_f, initial_p, rt_p, cv_p, representative_p, ion_p) rownames(df) &lt;- c(&quot;HILIC pos&quot;, &quot;HILIC neg&quot;, &quot;RP pos&quot;, &quot;RP neg&quot;) library(kableExtra) kable(df, col.names = c(&quot;initial&quot;, &quot;RT &gt;45 s&quot;, &quot;CV &lt;30%&quot;, &quot;repr. feat.&quot;, &quot;ion&quot;, &quot;initial&quot;, &quot;RT &gt;45 s&quot;, &quot;CV &lt;30%&quot;, &quot;repr. feat.&quot;, &quot;ion&quot;), longtable = T, booktabs = T, caption = &quot;Number of features and pc groups remaining after each filtering step.&quot;) %&gt;% add_header_above(c(&quot;&quot;, features = 5, `pc groups` = 5)) %&gt;% kable_styling(bootstrap_options = &quot;condensed&quot;, full_width = T) (#tab:kable_table)Number of features and pc groups remaining after each filtering step. features pc groups initial RT &gt;45 s CV &lt;30% repr. feat. ion initial RT &gt;45 s CV &lt;30% repr. feat. ion HILIC pos 5113 4389 3507 2212 105 3298 2781 2212 2212 79 HILIC neg 4049 3081 2808 1351 123 2044 1495 1351 1351 62 RP pos 5821 5588 4673 2736 171 3420 3277 2736 2736 128 RP neg 3867 3621 3166 1678 105 2069 1918 1678 1678 80 library(reshape2) df &lt;- melt(df) df[&quot;filter&quot;] &lt;- c(rep((&quot;initial&quot;), 4), rep((&quot;RT &gt;45 s&quot;), 4), rep((&quot;CV &lt;30%&quot;), 4), rep((&quot;rep&quot;), 4), rep((&quot;ion&quot;), 4)) df$filter &lt;- factor(df$filter, levels = c(&quot;initial&quot;, &quot;RT &gt;45 s&quot;, &quot;CV &lt;30%&quot;, &quot;rep&quot;, &quot;ion&quot;)) df[&quot;category&quot;] &lt;- c(rep((&quot;feature&quot;), 20), rep((&quot;pc group&quot;), 20)) df$Var2 &lt;- NULL colnames(df) &lt;- c(&quot;acquisition&quot;, &quot;value&quot;, &quot;filter&quot;, &quot;category&quot;) library(ggplot2) ggplot(df, aes(fill = df$filter, x = df$acquisition, y = df$value)) + geom_bar(position = &quot;dodge&quot;, stat = &quot;identity&quot;) + facet_grid(. ~ df$category) + xlab(&quot;Data acquisition mode&quot;) + ylab(&quot;Count&quot;) + labs(fill = &quot;Filtering step&quot;) + theme_bw() + scale_fill_grey() + scale_y_continuous(breaks = seq(0, 6000, 1000)) + theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust = 0.5), legend.position = &quot;bottom&quot;) After preliminary analyses of metabolomics data, a few outliers were re-identified by P. Cárdenas, and one specimen was removed from the data set as it originated from another species. 2.3 Multivariate analyses I order to investigate whether depth has an effect on the overall metabolome, we use OPLS orthogonal projections of latent structures as multivariate analysis approach. This method allows to separate variations in the data based on e.g. depth and orthogonal, i.e. unrealted variation. library(ropls) library(dplyr) library(ggplot2) # load data hilic_pos &lt;- read.csv(&quot;data/HILIC_pos_20190417_cleaned.csv&quot;, header = T, sep = &quot;,&quot;) hilic_neg &lt;- read.csv(&quot;data/HILIC_neg_20190421_cleaned.csv&quot;, header = T, sep = &quot;,&quot;) rp_pos &lt;- read.csv(&quot;data/RP_pos_20190421_cleaned.csv&quot;, header = T, sep = &quot;,&quot;) rp_neg &lt;- read.csv(&quot;data/RP_neg_20190422_cleaned.csv&quot;, header = T, sep = &quot;,&quot;) meta_data &lt;- read.csv(&quot;data/Steffen_et_al_metadata_PANGAEA.csv&quot;, header = T, sep = &quot;;&quot;) formatting &lt;- function(metabolome, meta_data, my_colnames) { formatted &lt;- metabolome formatted &lt;- formatted[, 14:(dim(formatted)[2] - 6)] formatted &lt;- data.frame(t(formatted)) formatted[&quot;ID&quot;] &lt;- rownames(formatted) formatted[&quot;unified_ID&quot;] &lt;- meta_data$unified_ID[match(formatted$ID, meta_data[[my_colnames]])] formatted[&quot;filter&quot;] &lt;- str_sub(formatted$unified_ID, 1, 2) formatted &lt;- formatted[!formatted$filter == &quot;QC&quot;, ] formatted &lt;- na.omit(formatted) # formatted$filter &lt;- NULL formatted$ID &lt;- NULL formatted &lt;- formatted[order(formatted$unified_ID), ] rownames(formatted) &lt;- formatted$unified_ID return(formatted) } hilic_pos &lt;- formatting(hilic_pos, meta_data, &quot;LC.MS.HILIC.positive&quot;) hilic_neg &lt;- formatting(hilic_neg, meta_data, &quot;LC.MS.HILIC.negative&quot;) rp_pos &lt;- formatting(rp_pos, meta_data, &quot;LC.MS.RP.positive&quot;) rp_neg &lt;- formatting(rp_neg, meta_data, &quot;LC.MS.RP.negative&quot;) md &lt;- meta_data[, c(&quot;Species&quot;, &quot;Depth&quot;, &quot;Latitude&quot;, &quot;Longitude&quot;, &quot;YEAR&quot;, &quot;MeanBottomTemp_Cdeg&quot;, &quot;MeanBotSalinity_PSU&quot;, &quot;unified_ID&quot;)] # Overview PCA illustrating the metabolomes differ by sponge species pca_wrapper &lt;- function(metabolome, md, my_title) { metabolome$unified_ID &lt;- NULL metabolome$filter &lt;- NULL metabolome &lt;- prcomp(metabolome, scale = T) k &lt;- summary(metabolome)[[&quot;importance&quot;]] metabolome_df &lt;- data.frame(metabolome$x) #scores, i.e. principal components of the sponge sample metabolome_df[&quot;unified_ID&quot;] &lt;- as.factor(rownames(metabolome_df)) x1 &lt;- paste(&quot;PC1&quot;, round(k[2, 1], digits = 3) * 100, &quot;%&quot;) y1 &lt;- paste(&quot;PC2&quot;, round(k[2, 2], digits = 3) * 100, &quot;%&quot;) metabolome_df &lt;- left_join(metabolome_df[, c(&quot;PC1&quot;, &quot;PC2&quot;, &quot;PC3&quot;, &quot;unified_ID&quot;)], md[, c(&quot;Species&quot;, &quot;Depth&quot;, &quot;Latitude&quot;, &quot;Longitude&quot;, &quot;MeanBottomTemp_Cdeg&quot;, &quot;MeanBotSalinity_PSU&quot;, &quot;unified_ID&quot;)]) p &lt;- ggplot(metabolome_df, aes(x = PC1, y = PC2)) + geom_point(size = 3, aes(shape = factor(Species))) + ggtitle(my_title) + xlab(x1) + ylab(y1) + theme(legend.position = &quot;none&quot;) #+labs(shape=&#39;Species&#39;) return(p) } hp_pca &lt;- pca_wrapper(hilic_pos, md, &quot;Hilic pos&quot;) hn_pca &lt;- pca_wrapper(hilic_neg, md, &quot;Hilic neg&quot;) rp_pca &lt;- pca_wrapper(rp_pos, md, &quot;RP pos&quot;) rn_pca &lt;- pca_wrapper(rp_neg, md, &quot;RP pos&quot;) # FUN multiplot # NOT MY OWN multiplot &lt;- function(..., plotlist = NULL, file, cols = 1, layout = NULL) { library(grid) # Make a list from the ... arguments and plotlist plots &lt;- c(list(...), plotlist) numPlots = length(plots) # If layout is NULL, then use &#39;cols&#39; to determine layout if (is.null(layout)) { # Make the panel ncol: Number of columns of plots nrow: Number of rows needed, # calculated from # of cols layout &lt;- matrix(seq(1, cols * ceiling(numPlots/cols)), ncol = cols, nrow = ceiling(numPlots/cols)) } if (numPlots == 1) { print(plots[[1]]) } else { # Set up the page grid.newpage() pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout)))) # Make each plot, in the correct location for (i in 1:numPlots) { # Get the i,j matrix positions of the regions that contain this subplot matchidx &lt;- as.data.frame(which(layout == i, arr.ind = TRUE)) print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row, layout.pos.col = matchidx$col)) } } } multiplot(hp_pca, hn_pca, rp_pca, rn_pca, cols = 2) library(vegan) permanova &lt;- function(metabolome, md) { metabolome$filter &lt;- NULL md &lt;- md[md$unified_ID %in% metabolome$unified_ID, ] metabolome &lt;- metabolome[order(metabolome$unified_ID), ] md &lt;- md[order(md$unified_ID), ] metabolome$unified_ID &lt;- NULL m &lt;- adonis(metabolome ~ Species, md) return(m) } permanova(hilic_pos, md) ## ## Call: ## adonis(formula = metabolome ~ Species, data = md) ## ## Permutation: free ## Number of permutations: 999 ## ## Terms added sequentially (first to last) ## ## Df SumsOfSqs MeanSqs F.Model R2 Pr(&gt;F) ## Species 2 5.6422 2.82112 34.302 0.62026 0.001 *** ## Residuals 42 3.4543 0.08224 0.37974 ## Total 44 9.0965 1.00000 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 permanova(hilic_neg, md) ## ## Call: ## adonis(formula = metabolome ~ Species, data = md) ## ## Permutation: free ## Number of permutations: 999 ## ## Terms added sequentially (first to last) ## ## Df SumsOfSqs MeanSqs F.Model R2 Pr(&gt;F) ## Species 2 2.0768 1.03838 26.046 0.55363 0.001 *** ## Residuals 42 1.6744 0.03987 0.44637 ## Total 44 3.7512 1.00000 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 permanova(rp_pos, md) ## ## Call: ## adonis(formula = metabolome ~ Species, data = md) ## ## Permutation: free ## Number of permutations: 999 ## ## Terms added sequentially (first to last) ## ## Df SumsOfSqs MeanSqs F.Model R2 Pr(&gt;F) ## Species 2 6.0969 3.04847 35.972 0.6314 0.001 *** ## Residuals 42 3.5593 0.08475 0.3686 ## Total 44 9.6563 1.0000 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 permanova(rp_neg, md) ## ## Call: ## adonis(formula = metabolome ~ Species, data = md) ## ## Permutation: free ## Number of permutations: 999 ## ## Terms added sequentially (first to last) ## ## Df SumsOfSqs MeanSqs F.Model R2 Pr(&gt;F) ## Species 2 6.4179 3.2089 36.013 0.63725 0.001 *** ## Residuals 41 3.6533 0.0891 0.36275 ## Total 43 10.0712 1.00000 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 From the PCA and the PERMANOVA, we gather that the metabolomes regardless of how they were acquired are significatly different in the three sponge species. Therefore, we separate the metabolomes for investigating the effect of depth on them individually. # splitting df and adapting meta data spl_ada &lt;- function(metabolome, md) { metabolome_gb &lt;- metabolome[metabolome$filter == &quot;Gb&quot;, ] metabolome_sf &lt;- metabolome[metabolome$filter == &quot;Sf&quot;, ] metabolome_wb &lt;- metabolome[metabolome$filter == &quot;Wb&quot;, ] md_gb &lt;- md[md$unified_ID %in% metabolome_gb$unified_ID, ] md_sf &lt;- md[md$unified_ID %in% metabolome_sf$unified_ID, ] md_wb &lt;- md[md$unified_ID %in% metabolome_wb$unified_ID, ] metabolome_gb &lt;- metabolome_gb[order(metabolome_gb$unified_ID), ] metabolome_sf &lt;- metabolome_sf[order(metabolome_sf$unified_ID), ] metabolome_wb &lt;- metabolome_wb[order(metabolome_wb$unified_ID), ] metabolome_gb$filter &lt;- NULL metabolome_gb$unified_ID &lt;- NULL metabolome_sf$filter &lt;- NULL metabolome_sf$unified_ID &lt;- NULL metabolome_wb$filter &lt;- NULL metabolome_wb$unified_ID &lt;- NULL md_gb &lt;- md_gb[order(md_gb$unified_ID), ] md_sf &lt;- md_sf[order(md_sf$unified_ID), ] md_wb &lt;- md_wb[order(md_wb$unified_ID), ] mva_data &lt;- list(metabolome_gb = metabolome_gb, metabolome_sf = metabolome_sf, metabolome_wb = metabolome_wb, md_gb = md_gb, md_sf = md_sf, md_wb = md_wb) return(mva_data) } hp_opls_df &lt;- spl_ada(hilic_pos, md) hn_opls_df &lt;- spl_ada(hilic_neg, md) rp_opls_df &lt;- spl_ada(rp_pos, md) rn_opls_df &lt;- spl_ada(rp_neg, md) ropls_wrapper &lt;- function(opls_df) { # ropls&#39; PCA gb.pca &lt;- opls(opls_df$metabolome_gb) sf.pca &lt;- opls(opls_df$metabolome_sf) wb.pca &lt;- opls(opls_df$metabolome_wb) md_gb &lt;- opls_df$md_gb md_sf &lt;- opls_df$md_sf md_wb &lt;- opls_df$md_wb # ropls&#39; OPLS gb.opls &lt;- opls(opls_df$metabolome_gb, md_gb[, &quot;Depth&quot;], permI = 10, orthoI = NA, scaleC = &quot;pareto&quot;) sf.opls &lt;- opls(opls_df$metabolome_sf, md_sf[, &quot;Depth&quot;], permI = 10, orthoI = NA, scaleC = &quot;pareto&quot;) wb.opls &lt;- opls(opls_df$metabolome_wb, md_wb[, &quot;Depth&quot;], permI = 10, orthoI = NA, scaleC = &quot;pareto&quot;) # summary gb.opls &lt;- gb.opls@summaryDF sf.opls &lt;- sf.opls@summaryDF wb.opls &lt;- wb.opls@summaryDF opls_diagnostics &lt;- rbind(gb.opls, sf.opls, wb.opls) opls_diagnostics[&quot;Species&quot;] &lt;- c(&quot;Geodia barretti&quot;, &quot;Stryphnus fortis&quot;, &quot;Weberella bursa&quot;) return(opls_diagnostics) } a &lt;- Sys.time() hp_cleaned_opls &lt;- ropls_wrapper(hp_opls_df) ## PCA ## 16 samples x 3507 variables ## standard scaling of predictors ## R2X(cum) pre ort ## Total 0.57 5 0 ## PCA ## 13 samples x 3507 variables ## standard scaling of predictors ## R2X(cum) pre ort ## Total 0.584 5 0 ## PCA ## 16 samples x 3507 variables ## standard scaling of predictors ## R2X(cum) pre ort ## Total 0.555 5 0 ## OPLS ## 16 samples x 3507 variables and 1 response ## pareto scaling of predictors and response(s) ## R2X(cum) R2Y(cum) Q2(cum) RMSEE pre ort pR2Y pQ2 ## Total 0.425 0.998 0.867 19.7 1 2 0.1 0.1 ## OPLS ## 13 samples x 3507 variables and 1 response ## pareto scaling of predictors and response(s) ## R2X(cum) R2Y(cum) Q2(cum) RMSEE pre ort pR2Y pQ2 ## Total 0.349 0.998 0.719 17.3 1 2 0.1 0.1 ## OPLS ## 16 samples x 3507 variables and 1 response ## pareto scaling of predictors and response(s) ## R2X(cum) R2Y(cum) Q2(cum) RMSEE pre ort pR2Y pQ2 ## Total 0.496 0.999 0.549 13.7 1 3 0.1 0.1 hn_cleaned_opls &lt;- ropls_wrapper(hn_opls_df) ## PCA ## 16 samples x 2808 variables ## standard scaling of predictors ## R2X(cum) pre ort ## Total 0.58 4 0 ## PCA ## 13 samples x 2808 variables ## standard scaling of predictors ## R2X(cum) pre ort ## Total 0.512 3 0 ## PCA ## 16 samples x 2808 variables ## standard scaling of predictors ## R2X(cum) pre ort ## Total 0.549 4 0 ## OPLS ## 16 samples x 2808 variables and 1 response ## pareto scaling of predictors and response(s) ## R2X(cum) R2Y(cum) Q2(cum) RMSEE pre ort pR2Y pQ2 ## Total 0.464 0.988 0.767 47.4 1 2 0.1 0.1 ## OPLS ## 13 samples x 2808 variables and 1 response ## pareto scaling of predictors and response(s) ## R2X(cum) R2Y(cum) Q2(cum) RMSEE pre ort pR2Y pQ2 ## Total 0.61 0.998 0.737 20.8 1 3 0.3 0.1 ## OPLS ## 16 samples x 2808 variables and 1 response ## pareto scaling of predictors and response(s) ## R2X(cum) R2Y(cum) Q2(cum) RMSEE pre ort pR2Y pQ2 ## Total 0.366 0.985 0.556 42.4 1 2 0.2 0.1 rp_cleaned_opls &lt;- ropls_wrapper(rp_opls_df) ## PCA ## 16 samples x 4673 variables ## standard scaling of predictors ## R2X(cum) pre ort ## Total 0.503 4 0 ## PCA ## 13 samples x 4673 variables ## standard scaling of predictors ## R2X(cum) pre ort ## Total 0.551 4 0 ## PCA ## 16 samples x 4673 variables ## standard scaling of predictors ## R2X(cum) pre ort ## Total 0.501 4 0 ## OPLS ## 16 samples x 4673 variables and 1 response ## pareto scaling of predictors and response(s) ## R2X(cum) R2Y(cum) Q2(cum) RMSEE pre ort pR2Y pQ2 ## Total 0.585 0.998 0.796 22.6 1 3 0.1 0.1 ## OPLS ## 13 samples x 4673 variables and 1 response ## pareto scaling of predictors and response(s) ## R2X(cum) R2Y(cum) Q2(cum) RMSEE pre ort pR2Y pQ2 ## Total 0.469 0.991 0.63 37.5 1 2 0.1 0.1 ## OPLS ## 16 samples x 4673 variables and 1 response ## pareto scaling of predictors and response(s) ## R2X(cum) R2Y(cum) Q2(cum) RMSEE pre ort pR2Y pQ2 ## Total 0.343 0.98 0.335 48.8 1 2 0.1 0.2 rn_cleaned_opls &lt;- ropls_wrapper(rn_opls_df) ## PCA ## 15 samples x 3166 variables ## standard scaling of predictors ## R2X(cum) pre ort ## Total 0.52 4 0 ## PCA ## 13 samples x 3166 variables ## standard scaling of predictors ## R2X(cum) pre ort ## Total 0.579 4 0 ## PCA ## 16 samples x 3166 variables ## standard scaling of predictors ## R2X(cum) pre ort ## Total 0.511 4 0 ## OPLS ## 15 samples x 3166 variables and 1 response ## pareto scaling of predictors and response(s) ## R2X(cum) R2Y(cum) Q2(cum) RMSEE pre ort pR2Y pQ2 ## Total 0.377 0.987 0.71 46.9 1 2 0.2 0.1 ## OPLS ## 13 samples x 3166 variables and 1 response ## pareto scaling of predictors and response(s) ## R2X(cum) R2Y(cum) Q2(cum) RMSEE pre ort pR2Y pQ2 ## Total 0.476 0.985 0.623 49.3 1 2 0.2 0.1 ## OPLS ## 16 samples x 3166 variables and 1 response ## pareto scaling of predictors and response(s) ## R2X(cum) R2Y(cum) Q2(cum) RMSEE pre ort pR2Y pQ2 ## Total 0.412 0.985 0.45 41.9 1 2 0.1 0.1 b &lt;- Sys.time() b - a ## Time difference of 1.315334 mins cleaned &lt;- rbind(hp_cleaned_opls, hn_cleaned_opls, rp_cleaned_opls, rn_cleaned_opls) cleaned[&quot;Experiment&quot;] &lt;- c(rep(&quot;HILIC pos&quot;, 3), rep(&quot;HILIC neg&quot;, 3), rep(&quot;RP pos&quot;, 3), rep(&quot;RP neg&quot;, 3)) write.csv(cleaned, &quot;data/cleaned_opls_diagnostics.csv&quot;, row.names = F) 2.4 Manual annotation, identification and extraction of metabolic feature signals 2.5 Correlations sessionInfo() ## R version 3.5.1 (2018-07-02) ## Platform: x86_64-apple-darwin15.6.0 (64-bit) ## Running under: macOS 10.14.6 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] grid stats graphics grDevices utils datasets methods ## [8] base ## ## other attached packages: ## [1] vegan_2.5-6 lattice_0.20-41 permute_0.9-5 ## [4] ropls_1.14.1 reshape2_1.4.3 kableExtra_1.1.0.9000 ## [7] ggplot2_3.3.0 stringr_1.4.0 dplyr_0.8.5 ## [10] knitr_1.28 ## ## loaded via a namespace (and not attached): ## [1] tidyselect_1.0.0 xfun_0.12 purrr_0.3.3 ## [4] splines_3.5.1 colorspace_1.4-1 vctrs_0.2.4 ## [7] htmltools_0.4.0 viridisLite_0.3.0 yaml_2.2.1 ## [10] mgcv_1.8-31 rlang_0.4.5 pillar_1.4.3 ## [13] glue_1.3.2 withr_2.1.2 BiocGenerics_0.28.0 ## [16] lifecycle_0.2.0 plyr_1.8.6 munsell_0.5.0 ## [19] gtable_0.3.0 rvest_0.3.5 evaluate_0.14 ## [22] labeling_0.3 Biobase_2.42.0 parallel_3.5.1 ## [25] fansi_0.4.1 highr_0.8 Rcpp_1.0.4 ## [28] readr_1.3.1 scales_1.1.0 formatR_1.7 ## [31] webshot_0.5.2 farver_2.0.3 hms_0.5.3 ## [34] digest_0.6.25 stringi_1.4.6 bookdown_0.18 ## [37] cli_2.0.2 tools_3.5.1 magrittr_1.5 ## [40] tibble_3.0.0 cluster_2.1.0 crayon_1.3.4 ## [43] pkgconfig_2.0.3 MASS_7.3-51.5 ellipsis_0.3.0 ## [46] Matrix_1.2-18 xml2_1.3.0 assertthat_0.2.1 ## [49] rmarkdown_2.1 httr_1.4.1 rstudioapi_0.11 ## [52] R6_2.4.1 nlme_3.1-145 compiler_3.5.1 "]
]
